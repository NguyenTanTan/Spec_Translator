{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8otpazu4YHcY",
        "outputId": "5957e408-061c-4859-db50-1d0f2a776c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.3.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.5)\n",
            "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "Successfully installed spacy-3.7.6\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install pyvi\n",
        "# !pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "# !python -m spacy download ja_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v345gQhKV_eX",
        "outputId": "eb1f10a9-4a37-4a19-f851-335623ca747f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To7COwUcYoIC"
      },
      "source": [
        "## Processing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kFHwR6csYUC"
      },
      "source": [
        "- EN-VN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_imU-CFsBv4",
        "outputId": "01768739-ffd5-42ef-f758-13f0588638d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('GARMENT', 'may mặc')\n",
            "('PATTERN', 'mẫu')\n",
            "('Placement', 'vị trí')\n",
            "('Part Code', 'mã phần')\n",
            "('Fiber Code & Content', 'mã sợi & nội dung')\n"
          ]
        }
      ],
      "source": [
        "# read data\n",
        "import string\n",
        "vi_input_ = []\n",
        "with open(\"/content/drive/MyDrive/hbi/data_vi\") as f:\n",
        "  for line in f:\n",
        "    line = line.replace('  ', ' ').lower()\n",
        "    vi_input_.append(line.strip())\n",
        "\n",
        "en_input_ = []\n",
        "with open(\"/content/drive/MyDrive/hbi/data_en\") as f:\n",
        "  for line in f:\n",
        "    en_input_.append(line.strip())\n",
        "\n",
        "for i in zip(en_input_[:5], vi_input_[:5]):\n",
        "  print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AFXh3p4hkT1"
      },
      "outputs": [],
      "source": [
        "# split_ratio = 0.02\n",
        "# split = round(len(en_input_)* split_ratio)\n",
        "# en_input = en_input_[:split]\n",
        "# vi_input = vi_input_[:split]\n",
        "en_input = en_input_\n",
        "vi_input = vi_input_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuDhkItSg5Rh",
        "outputId": "5ed0c5ab-a76b-45fe-9396-f834e8377524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "496\n",
            "496\n"
          ]
        }
      ],
      "source": [
        "print(len(en_input))\n",
        "print(len(vi_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQZnvU7YJL0"
      },
      "outputs": [],
      "source": [
        "# Thêm token đánh dấu điểm bắt đầu và kết thúc của câu vào mỗi câu trong ngôn ngữ đích\n",
        "eos = '<eos>'\n",
        "bos = '<bos>'\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "from pyvi import ViTokenizer\n",
        "vi_input_tokenize = [ViTokenizer.tokenize(i).split() for i in vi_input]\n",
        "for i in range(len(vi_input_tokenize)):\n",
        "  vi_input_tokenize[i].insert(0, bos)\n",
        "  vi_input_tokenize[i].insert(len(vi_input_tokenize[i]), eos)\n",
        "\n",
        "import spacy\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "en_input_tokenize = [[tok.text for tok in spacy_en.tokenizer(text)] for text in en_input]\n",
        "for i in range(len(en_input_tokenize)):\n",
        "  en_input_tokenize[i].insert(0, bos)\n",
        "  en_input_tokenize[i].insert(len(en_input_tokenize[i]), eos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc_v5vIR74NF",
        "outputId": "f71aac30-9060-4757-d827-3340ef3824dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<bos>', 'GARMENT', '<eos>']\n",
            "['<bos>', 'may_mặc', '<eos>']\n"
          ]
        }
      ],
      "source": [
        "print(en_input_tokenize[0])\n",
        "print(vi_input_tokenize[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb-zK9-aYJvA",
        "outputId": "58d16533-92af-442d-c402-b3030a9203d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<bos>': 1, '<eos>': 2, '\"': 3, 'to': 4, '.': 5, 'for': 6, '-': 7, 'updated': 8, 'width': 9, 'version': 10, 'fly': 11, ')': 12, 'added': 13, 'by': 14, '(': 15, ',': 16, 'and': 17, 'new': 18, 'opening': 19, 'marker': 20, 'from': 21, 'email': 22, 'of': 23, 'mfg': 24, 'panel': 25, 'spec': 26, '/': 27, 'hem': 28, 'at': 29, 'as': 30, 'pattern': 31, 'adding': 32, 'plant': 33, 'length': 34, 'waist': 35, '&': 36, 'change': 37, 'cut': 38, 'front': 39, 'the': 40, 'requested': 41, 'fabric': 42, 'garment': 43, 'update': 44, 'reduce': 45, '+': 46, '”': 47, ';': 48, 'measurement': 49, 'back': 50, 'id': 51, 'routing': 52, 'previous': 53, 'again': 54, 'previously': 55, 'it': 56, 'was': 57, 'following': 58, 'half': 59, 'leg': 60, 'binding': 61, 'on': 62, 'cost': 63, 'top': 64, '“': 65, 'color': 66, 'inner': 67, 'down': 68, 'add': 69, 'seam': 70, 'sling': 71, 'sew': 72, 'saving': 73, 'additional': 74, 'in': 75, 'pom': 76, '5': 77, 'usage': 78, 'bai': 79, 'bottom': 80, 'code': 81, 'size': 82, 'label': 83, 'position': 84, 'phu': 85, 'reduced': 86, 'thread': 87, 'project': 88, 'waistband': 89, 'edge': 90, 'page': 91, 'flatseam': 92, 'details': 93, 'fgm': 94, 'side': 95, 'style': 96, 'height': 97, 'outer': 98, 'please': 99, 'refer': 100, 'site': 101, 'use': 102, 'create': 103, 'task': 104, 'rise': 105, 'base': 106, 'dcr': 107, 'renamed': 108, '–': 109, '-inner': 110, 'elastic': 111, 'with': 112, 'information': 113, 'alt': 114, 'construction': 115, 'bom': 116, 'see': 117, 'a': 118, 'colorway': 119, 'addition': 120, 'product': 121, '1': 122, 'trim': 123, '2': 124, '3': 125, 'all': 126, 'mfgs': 127, 'move': 128, 'overedge': 129, 'sourced': 130, 'layout': 131, 'ver': 132, 'print': 133, '12': 134, 'tolerance': 135, 'up': 136, 'hung': 137, 'yen': 138, 'bind': 139, 'inside': 140, 'panels': 141, 'set': 142, 'plants': 143, 'baxa': 144, 'based': 145, 'ref': 146, 'overlap': 147, 'pouch': 148, 'placement': 149, 'part': 150, '8': 151, '10': 152, 'image': 153, '54': 154, 'd': 155, 'operation': 156, ':': 157, 'updating': 158, 'across': 159, '5s': 160, '16': 161, 'changing': 162, 'sleeve': 163, 'reduction': 164, 'gusset': 165, '58': 166, 'name': 167, 'type': 168, 'extended': 169, '7': 170, 'meas': 171, 'h5': 172, 'm': 173, 'trimoff': 174, '1/4': 175, 'request': 176, 'follow': 177, 'tack': 178, 'crotch': 179, 'attach': 180, 'sweep': 181, 'neck': 182, 'only': 183, 'no': 184, '2023': 185, 'styles': 186, 'i': 187, '60': 188, 'je2c59': 189, '3/16': 190, 'or': 191, '#': 192, 'min': 193, '6': 194, '4': 195, 'inseam': 196, 'finished': 197, 't148': 198, 't148h3': 199, 't148h3xl': 200, '2021': 201, '1/8': 202, '78': 203, 's22': 204, 's3': 205, 'data': 206, '87ss': 207, 'solid': 208, 'needle': 209, 'outside': 210, 'wb': 211, 'thpu': 212, '90': 213, 'shoulder': 214, 'hw3u': 215, 'savings': 216, 'changed': 217, 'using': 218, 'tolerances': 219, 'one': 220, 'be': 221, 'h2': 222, 'h3': 223, 'h4': 224, 'h6': 225, 'h7': 226, 'h8': 227, 'h81': 228, 'h82': 229, 'h83': 230, 'alternate': 231, 'pieces': 232, 'spi': 233, 'cf': 234, 'prf859': 235, '320': 236, 'layer': 237, 'description': 238, 'make': 239, 'date': 240, 'administrator': 241, 'general': 242, 'attributes': 243, 'hip': 244, 'seat': 245, 'folded': 246, 'total': 247, 'outseam': 248, 't148h5': 249, 'account': 250, '3/4': 251, '14': 252, '87hh': 253, '87sh': 254, '87hs': 255, '87ds': 256, 'stitch': 257, 'allowance': 258, 'exposed': 259, 'h': 260, 'spsa': 261, 'trom': 262, 'rtds': 263, 'kj': 264, 'pmeas': 265, 'per': 266, 'cyl': 267, 'basa': 268, 'due': 269, 'straight': 270, 'e': 271, '67/65': 272, 'ad025d1;change': 273, '62/59': 274, 'ad025d6': 275, 'corners': 276, 'c2': 277, 'seams': 278, 'separate': 279, 'direction': 280, 'wide': 281, 'shrinkage': 282, 'skewness': 283, 'improvement(reduce': 284, 'lenght': 285, 'an': 286, 'average': 287, 'rate': 288, 'colors': 289, 'changes': 290, 'layers': 291, 'mobilon': 292, 'c': 293, 't18': 294, \"'s\": 295, 'fiber': 296, 'content': 297, 'piece': 298, 'buy': 299, 'knit': 300, 'designer': 301, 'method': 302, 'active': 303, 'manager': 304, 'issued': 305, 'trunk': 306, 'flat': 307, 't148h4': 308, 't148h3l': 309, '20': 310, '21': 311, '95': 312, '9': 313, '2022': 314, 't148h.': 315, '1/3': 316, '13': 317, '15': 318, '28': 319, '79': 320, 'pgu': 321, 'img': 322, '002': 323, '11': 324, 'sewing': 325, 'gauge': 326, 'visibility': 327, 'looper': 328, 'latch': 329, 'circular': 330, 'another': 331, '3/8&quot': 332, 'break': 333, 'open': 334, 'gp': 335, '2e': 336, '2p': 337, '8b': 338, 'mbtd': 339, 'removed': 340, '106a': 341, 'elcatex': 342, 'ash': 343, 'gray': 344, 'eku': 345, 'hlhn': 346, 'tsu': 347, 'honduras': 348, 'dc': 349, 'g4': 350, 'bust': 351, 'chest': 352, '-(half': 353, 'armhole': 354, 'sides': 355, 'tubular': 356, 'dart': 357, 'wf': 358, 'needed': 359, '32': 360, 's': 361, 'elsal': 362, 'g': 363, '504': 364, 'drop': 365, 'mitered': 366, 'ad025d8': 367, 'ad025d9': 368, 'ad025d5,d6,d7': 369, 'way': 370, 'cutting': 371, 'printed': 372, 'fabrics': 373, 'must': 374, 'sewn': 375, 'same': 376, 'minimize': 377, 'torquing': 378, 'directional': 379, 'prints': 380, 'is': 381, 'internal': 382, 'gm': 383, 'aps': 384, 'h.': 385, '13.25': 386, '13.5': 387, 'i2': 388, '1/42': 389, '13.252': 390, '13.52': 391, 'i3': 392, '1/43': 393, '13.253': 394, '13.53': 395, 'i4': 396, '1/44': 397, '13.254': 398, '13.54': 399, 'i5': 400, '1/45': 401, '13.255': 402, '13.55': 403, 'i6': 404, '1/46': 405, '13.256': 406, '13.56': 407, 'i7': 408, '1/47': 409, '13.257': 410, '13.57': 411, 'i8': 412, '1/48': 413, '13.258': 414, '13.58': 415, 'i81': 416, '1/481': 417, '13.1': 418, '13.11': 419, 'i82': 420, '1/482': 421, '13.2': 422, '13.22': 423, 'i83': 424, '1/483': 425, '13.3': 426, '13.33': 427, 't148i2': 428, 'rbw649': 429, '35.5': 430, 't148i1': 431, 't148i3': 432, 't148i4': 433, '3.42': 434, '%': 435, 'mops': 436, 'load': 437, 's23': 438, 'used': 439, 'ae923a4': 440, 'ae923a5': 441, 'how': 442, 'measure': 443, 'more': 444, 'any': 445, 'other': 446, 'ae924a1': 447, 'ae924a2': 448, 'rev': 449, '8gg': 450, 'replace': 451, 'center': 452, 'horizontally': 453, 'vertically': 454, 'assembly': 455, '1/2': 456, 'this': 457, 's21': 458, 'cold': 459, 'water': 460, 't0351a': 461, 't0351b': 462, 'sizes': 463, 'ad025a': 464, 'b': 465, 'hlsn': 466, '01': 467, 'prw649': 468, '70': 469, 'prw651': 470, '72': 471, 'material': 472, 'divison': 473, 'primary': 474, 'manufactured': 475, 'manf': 476, 'comments': 477, 'last': 478, 'edited': 479, 'modified': 480, 'imperfect': 481, 'irregular': 482, 'technical': 483, 'brand': 484, 'specification': 485, 'hbi': 486, 'division': 487, '63': 488, 'idion': 489, '9kkk': 490, 't1': 491, 'th5': 492, '8h3l': 493, '221': 494, '955': 495, '995': 496, '222': 497, 't14': 498, '22': 499, 't8h.': 500, '202': 501, '204': 502, '148h4': 503, '205': 504, '148h5': 505, '206': 506, '148h6': 507, '207': 508, '148h7': 509, '208': 510, '148h8': 511, '134': 512, '135': 513, '136': 514, '137': 515, '138': 516, '7/8': 517, '18': 518, '67': 519, '34': 520, '84': 521, '44': 522, '85': 523, '45': 524, '86': 525, '46': 526, '53': 527, '25': 528, '76': 529, '26': 530, '77': 531, '3/41': 532, '55': 533, '27': 534, '3/42': 535, '56': 536, '3/43': 537, '57': 538, '29': 539, '3/44': 540, 's89': 541, 'pguimg': 542, '22s': 543, 'pgug': 544, '45s': 545, 'surin': 546, 'yun': 547, 'white': 548, 'y00': 549, 'yu2': 550, 'yunwhite': 551, 'yun002': 552, 'r': 553, '92': 554, '96': 555, '3432': 556, '344': 557, '3r3r': 558, '343': 559, 'rc2': 560, '11s': 561, '33': 562, 'type/': 563, 'item': 564, 'descrn': 565, 'coverstitch': 566, '87663': 567, 'mens': 568, 'boxer': 569, 'brief': 570, 'expwb': 571, '12/07/2023': 572, 'strap': 573, 'heigh': 574, 'non': 575, 'parts': 576, 'neckline': 577, 'armholes': 578, 'shoulders': 579, 'blind': 580, 'chainoffs': 581, 'fro': 582, 'k': 583, '8q': 584, 'option': 585, 'el': 586, 'salvador': 587, '3,4,5,6': 588, 'l': 589, '5,6': 590, 'cylinder': 591, '17': 592, '3764lw': 593, '30': 594, 'f': 595, 'hps': 596, 'pane': 597, 'collar': 598, 'cbn': 599, 'upper': 600, 'slope': 601, 'coincide': 602, 'current': 603, '<': 604, '23': 605, '100': 606, 'spread': 607, 'allowed': 608, 'two': 609, 'plies': 610, 'ad025a8': 611, 'include': 612, 'note': 613, 'about': 614, 'accepted': 615, 'sca': 616, '303381': 617, '303804': 618, 'fold': 619, 'contour': 620, 's25': 621, 'aqop': 622, 'h9c': 623, 'mobh': 624, '@877853': 625, 's24': 626, 'ruf': 627, 'mobs': 628, 'augu': 629, '@240322': 630, 'ae590c1;ae590c2;ae590c3': 631, 'ae590a3': 632, 'bhc': 633, '330101': 634, 'f22': 635, '314561': 636, 'facing': 637, 'seaming': 638, 'where': 639, '607': 640, 'not': 641, 'available': 642, 'capacity': 643, 'requires': 644, 'prior': 645, 'approval': 646, '338242': 647, 'urban': 648, 'outfitters': 649, '8i2': 650, 'r148i4': 651, '341150': 652, 'gp174922': 653, 'bag': 654, 'out': 655, 'assemble': 656, 'together': 657, 'hidden': 658, 'along': 659, 'through': 660, 'staystitch': 661, 'notch': 662, 'care': 663, '298191': 664, 'pi': 665, 'myfit': 666, 'addtion': 667, 't0351b7': 668, 'tx2f81': 669, 'improvement': 670, 'operations': 671, '277761': 672, '277762': 673, '277763': 674, '277764': 675, '277765': 676, 'f20': 677, '261897': 678, '1new': 679, 'tnw': 680, 'team': 681, 'wash': 682, 'pad': 683, 'stamp': 684, '57c': 685, '38p-': 686, 'spandex': 687, '19': 688, 'if': 689, 'becomes': 690, 'sp20': 691, 'g414': 692, 'purchased': 693, '1xe': 694, 'ukb': 695, 'tm0': 696, 'pxf': 697, 'hcu': 698, '5su': 699, 'vyu': 700, 'wash.': 701, 'remove': 702, 'uses': 703, 'incremented': 704, 's20': 705, 'ad025c.': 706, 'miter': 707, 't24st': 708, 'ud5c': 709, '259701': 710, 't24': 711, 'production': 712, 'reverted': 713, 'royalty': 714, 'blue': 715, 't': 716, 'mnh': 717, 'trademark': 718, 'f24': 719, 'mfg\"s': 720, 'assortment': 721, 'dplm': 722, 'cylinders': 723, 'hlmn': 724, 'tgpc': 725, 'pass': 726, 's-2x': 727, 'apss': 728, 'ssps': 729, 'created': 730, '1.25': 731, 'form': 732, '11.25': 733, 'max': 734, 't148i5': 735, 'rcm': 736, 'still': 737, 'keep': 738, 'factory': 739, 'inventory': 740, 'has': 741, 'been': 742, 'order': 743, 'idea': 744, '4/5': 745, 'ae9': 746, 'pr': 747, '341149': 748, 'gp175895': 749}\n",
            "749\n",
            "{'<bos>': 1, '<eos>': 2, '\"': 3, '.': 4, 'cập_nhật': 5, 'chiều': 6, 'thêm': 7, '-': 8, 'được': 9, '/': 10, 'cho': 11, 'rộng': 12, 'phiên_bản': 13, 'túi': 14, 'trước': 15, '(': 16, ')': 17, 'đã': 18, 'lên': 19, 'miệng': 20, 'theo': 21, 'và': 22, 'bên': 23, ',': 24, 'rập': 25, 'mới': 26, 'giảm': 27, 'từ': 28, 'trong': 29, 'email': 30, 'đường': 31, 'mảnh': 32, 'thông_số': 33, 'mở': 34, 'thay_đổi': 35, 'mfg': 36, 'may': 37, 'của': 38, 'kỹ_thuật': 39, '1': 40, 'viền': 41, 'độ': 42, 'để': 43, 'cắt': 44, 'trên': 45, 'dài': 46, 'ở': 47, 'phía': 48, 'đi': 49, 'vào': 50, 'nhà_máy': 51, 'yêu_cầu': 52, 'qua': 53, 'đó': 54, 'xuống': 55, 'sử_dụng': 56, 'màu': 57, 'vải': 58, '&': 59, 'lưng': 60, 'một': 61, ';': 62, 'các': 63, '”': 64, 'mẫu': 65, 'bổ_sung': 66, 'dây': 67, 'id': 68, '+': 69, 'là': 70, 'may_mặc': 71, 'số_đo': 72, '3': 73, 'định_tuyến': 74, 'trang': 75, 'thành': 76, 'có': 77, 'lại': 78, 'đùi': 79, 'tiết_kiệm': 80, 'chi_phí': 81, 'biết': 82, '“': 83, 'vị_trí': 84, 'nửa': 85, 'hàng': 86, 'ngoài': 87, 'chỉ': 88, 'thắt_lưng': 89, 'sau': 90, 'bìa': 91, 'cách': 92, 'tham_khảo': 93, 'phần': 94, 'kiểu': 95, 'pom': 96, 'kích_thước': 97, 'tên': 98, 'đeo': 99, 'mã': 100, '5': 101, 'bài': 102, 'nhãn': 103, '4': 104, '8': 105, 'phú': 106, 'dự_án': 107, 'cao': 108, 'cạnh': 109, 'phẳng': 110, 'chi_tiết': 111, 'fgm': 112, 'tạo': 113, 'dựa': 114, 'in': 115, 'dung_sai': 116, 'vui_lòng': 117, 'dưới': 118, 'mặt': 119, '16': 120, '2': 121, 'dcr': 122, 'mở_miệng': 123, 'đổi': 124, '–': 125, 'thông_tin': 126, 'alt': 127, 'bom': 128, 'nhà_máy_may': 129, 'về': 130, 'ràng_buộc': 131, 'xem': 132, 'nhiệm_vụ': 133, 'không': 134, '12': 135, 'tất_cả': 136, 'mfgs': 137, 'di_chuyển': 138, 'vắt_sổ': 139, 'đáy': 140, 'nguồn_gốc': 141, 'bố_cục': 142, 'lớp': 143, 'loại': 144, 'hưng_yên': 145, 'cùng': 146, 'cổ': 147, 'baxa': 148, 'với': 149, 'miếng': 150, 'sản_phẩm': 151, 'hoạt_động': 152, 'nâng': 153, '10': 154, '54': 155, 'd': 156, 'tấm': 157, ':': 158, '2023': 159, '5s': 160, 'tay_áo': 161, 'lót': 162, 'thay_thế': 163, '58': 164, 'chồng_chéo': 165, 'sản_xuất': 166, 'mở_rộng': 167, '7': 168, 'h5': 169, 'đế': 170, 'dự_phòng': 171, 'bớt': 172, 'khâu': 173, 'thun': 174, 'quần': 175, 'gắn': 176, 'đặt': 177, 'h': 178, 'vai': 179, 's': 180, 'ver': 181, 'mô_hình': 182, 'i': 183, '60': 184, 'je2c59': 185, 'hoặc': 186, 'ngày': 187, 'tối_thiểu': 188, 'nữa': 189, 'gập': 190, 'đóng': 191, 'ảnh': 192, 'thành_phẩm': 193, 't148': 194, 't148h3m': 195, '2021': 196, '67': 197, '44': 198, '78': 199, 's22': 200, 's3': 201, 'dữ_liệu': 202, '87ss': 203, 'đo': 204, 'trơn': 205, 'kim': 206, 'bằng': 207, 'khác': 208, 'wb': 209, 'thpu': 210, '\\u200b': 211, '90': 212, 'hw3u': 213, 'góc': 214, 'hướng': 215, 'h2': 216, 'h3': 217, 'h4': 218, 'h6': 219, 'h7': 220, 'h8': 221, 'h81': 222, 'h82': 223, 'h83': 224, 'spi': 225, 'cf': 226, 'prf859': 227, '320': 228, 'làm': 229, 'mua': 230, 'quản_trị': 231, 'viên': 232, '#': 233, 'thuộc_tính': 234, 'chung': 235, 'tăng': 236, '6': 237, 'hông': 238, 'ghế': 239, 'tổng_cộng': 240, 'cắt_xén': 241, 't148h5': 242, 't148h3xl': 243, 'tính': 244, '14': 245, '45': 246, '46': 247, '42': 248, '43': 249, '87hh': 250, '87sh': 251, '87hs': 252, '87ds': 253, 'thao_tác': 254, 'mô_tả': 255, 'dây_thun': 256, 'hở': 257, 'đang': 258, 'spsa': 259, 'quét': 260, 'dán': 261, 'trom': 262, 'rtds': 263, 'kj': 264, 'cần': 265, 'pmeas': 266, 'trụ': 267, 'basa': 268, 'sang': 269, 'do': 270, 'thẳng': 271, 'phiên_bản_mẫu': 272, 'cấu_trúc': 273, 'e': 274, '65': 275, 'ad025d1': 276, '62': 277, '59': 278, 'ad025d6': 279, 'c2': 280, 'new': 281, 'wide': 282, 'cải_thiện': 283, 'co': 284, 'lệch': 285, 'tỷ_lệ': 286, 'trung_bình': 287, 'xây_dựng': 288, 'lắp_ráp': 289, 'mobilon': 290, 'dọc': 291, 'c': 292, 't18': 293, 'đến': 294, 'sợi': 295, 'bộ_phận': 296, 'sự': 297, 'nhà': 298, 'thiết_kế': 299, 'phương_pháp': 300, 'thi_công': 301, 'giám_đốc': 302, 'phát_hành': 303, 'thân': 304, 'bằng_phẳng': 305, 'hoàn_thành': 306, 't148h4': 307, 't148h3l': 308, '20': 309, '21': 310, '95': 311, '9': 312, '2022': 313, 't148h': 314, '13': 315, '15': 316, '28': 317, '79': 318, 'pgu': 319, 'img': 320, '002': 321, '11': 322, 'mũi': 323, 'phân_chia': 324, 'tầm': 325, 'nhìn': 326, 'looper': 327, 'chốt': 328, 'cài': 329, 'tới': 330, 'tròn': 331, 'quot': 332, 'đàn_hồi': 333, 'gp': 334, '2e': 335, '2p': 336, '8b': 337, 'mbtd': 338, 'xóa_quét': 339, '106a': 340, 'elcatex': 341, 'ash': 342, 'grey': 343, 'eku': 344, 'hlhn': 345, 'tsu': 346, 'honduras': 347, 'dc': 348, 'g4': 349, 'bán_thân': 350, 'ngực': 351, 'armhole': 352, 'ống': 353, 'áo': 354, 'phi_tiêu': 355, 'cây': 356, 'wf': 357, '32': 358, 'elsal': 359, '504': 360, 'thả': 361, 'hình_ảnh': 362, 'liên_kết': 363, 'nhẹ': 364, 'ad025d8': 365, 'ad025d9': 366, 'ad025d5': 367, 'd6': 368, 'd7': 369, 'thiết_lập': 370, 'một_chiều': 371, 'phép': 372, 'nối': 373, 'hai': 374, 'phải': 375, 'giảm_thiểu': 376, 'lực': 377, 'xoắn': 378, 'bản': 379, 'đối_với': 380, 'mỗi': 381, 'tác': 382, 'vụ': 383, 'gm': 384, 'aps': 385, '13,25': 386, '13,5': 387, 'i2': 388, '13,252': 389, '13,52': 390, 'i3': 391, '13,253': 392, '13,53': 393, 'i4': 394, '13,254': 395, '13,54': 396, 'i5': 397, '13,255': 398, '13,55': 399, 'i6': 400, '13,256': 401, '13,56': 402, 'i7': 403, '47': 404, '13,257': 405, '13,57': 406, 'i8': 407, '48': 408, '13,258': 409, '13,58': 410, 'i81': 411, '481': 412, '13,1': 413, '13,11': 414, 'i82': 415, '482': 416, '13,2': 417, '13,22': 418, 'i83': 419, '483': 420, '13,3': 421, '13,33': 422, 't148i2': 423, 'rbw649': 424, '35.5': 425, 't148i1': 426, 't148i3': 427, 't148i4': 428, '3,42': 429, '%': 430, 'mops': 431, '@': 432, 'tải': 433, 's23': 434, 'tại': 435, 'ae923a4': 436, 'ae923a5': 437, 'bất_kỳ': 438, 'nào': 439, 'ae924a1': 440, 'ae924a2': 441, 'rev': 442, '8gg': 443, 'giữa': 444, 'riêng_biệt': 445, 'nhau': 446, 'ngang': 447, 'cánh': 448, 'này': 449, 's21': 450, 'giặt': 451, 'nước_lạnh': 452, 't0351a': 453, 't0351b': 454, 'mức': 455, 'ad025a': 456, 'b': 457, 'a': 458, 'hlsn': 459, '01': 460, 'prw649': 461, '70': 462, 'prw651': 463, '72': 464, 'nội_dung': 465, 'vật_liệu': 466, 'miêu_tả': 467, 'sơ_đẳng': 468, 'đan': 469, 'bình_luận': 470, 'chỉnh_sửa': 471, 'lần': 472, 'cuối': 473, 'bởi': 474, 'sửa_đổi': 475, 'hoàn_hảo': 476, 'độc_đáo': 477, 'thương_hiệu': 478, 'đặc_điểm': 479, 'hbi': 480, '63': 481, 'idion': 482, '9kkk': 483, 't1': 484, 'th5': 485, '8h3l': 486, '221': 487, '955': 488, '995': 489, '222': 490, 't14': 491, '22': 492, 't8h': 493, '202': 494, '204': 495, '148h4': 496, '205': 497, '148h5': 498, '206': 499, '148h6': 500, '207': 501, '148h7': 502, '208': 503, '148h8': 504, '134': 505, '135': 506, '136': 507, '137': 508, '138': 509, '18': 510, '34': 511, '84': 512, '85': 513, '86': 514, '53': 515, '25': 516, '76': 517, '26': 518, '77': 519, '41': 520, '55': 521, '27': 522, '56': 523, '57': 524, '29': 525, 's89': 526, 'pguimg': 527, '22s': 528, 'pgug': 529, '45s': 530, 'surin': 531, 'cut': 532, 'sew': 533, 'yun': 534, 'trắng': 535, 'y00': 536, 'yu2': 537, 'yunwhite': 538, 'yun002': 539, 'r': 540, '92': 541, '96': 542, '3432': 543, '344': 544, '3r3r': 545, '343': 546, 'rc2': 547, '11s': 548, '33': 549, 'mặt_hàng': 550, 'ngắt': 551, '87663': 552, 'mens': 553, 'knit': 554, 'boxer': 555, 'brief': 556, 'expwb': 557, 'mẫu_số': 558, '07': 559, 'mặt_đường': 560, 'dành': 561, 'hình': 562, 'nách': 563, 'mù': 564, 'dây_xích': 565, 'quần_áo': 566, '7k': 567, '8q': 568, 'tùy': 569, 'chọn': 570, 'el': 571, 'salvador': 572, '3,4,5,6': 573, 'l': 574, 'm': 575, '5,6': 576, 'thay': 577, 'xi_lanh': 578, '17': 579, '3764lw': 580, '30': 581, 'f': 582, 'g': 583, 'hps': 584, 'break': 585, 'qua_mặt': 586, 'cbn': 587, 'dốc': 588, 'công_trình': 589, 'trùng': 590, 'hiện_tại': 591, '<': 592, '23': 593, '100': 594, 'lây_lan': 595, 'tách': 596, 'ad025a8': 597, 'bao_gồm': 598, 'ghi_chú': 599, 'định_hướng': 600, 'chấp_nhận': 601, 'sca': 602, '303381': 603, 'internal': 604, '303804': 605, 'nhô': 606, 's25': 607, 'aqop': 608, 'h9c': 609, 'mobh': 610, '877853': 611, 's24': 612, 'ruf': 613, 'mobs': 614, 'augu': 615, '240322': 616, 'ae590c1': 617, 'ae590c2': 618, 'ae590c3': 619, 'ae590a3': 620, '5g': 621, 'bhc': 622, '330101': 623, 'f22': 624, '314561': 625, 'khi': 626, '607': 627, 'sức_chứa': 628, 'phê_duyệt': 629, '338242': 630, 'urban': 631, 'outfitters': 632, '8i2': 633, 'r148i4': 634, '341150': 635, 'gp174922': 636, 'đóng_gói': 637, 'giấu': 638, 'xuyên': 639, 'chồng': 640, 'khía': 641, 'chăm_sóc': 642, 'họa': 643, 'tiết': 644, '298191': 645, 'pi': 646, 'myfit': 647, 't0351b7': 648, 'tx2f81': 649, 'cải_tiến': 650, 'tham_chiếu': 651, '277761': 652, '277762': 653, '277763': 654, '277764': 655, '277765': 656, 'f20': 657, '261897': 658, 'tnw': 659, 'nhóm': 660, 'tem': 661, 'pad': 662, 'hàm_lượng': 663, '57c': 664, '38p': 665, 'spandex': 666, '19': 667, 'nếu': 668, 'sp20': 669, 'g414': 670, 'nội_bộ': 671, '1xe': 672, 'ukb': 673, 'tm0': 674, 'pxf': 675, 'hcu': 676, '5su': 677, 'vyu': 678, 'xóa': 679, 's20': 680, 'ad025c': 681, 'vát': 682, 't24st': 683, 'ud5c': 684, '259701': 685, 't24': 686, 'hoàn_nguyên': 687, 'royal': 688, 'blue': 689, '6t': 690, 'mnh': 691, 'nhãn_hiệu': 692, 'treo': 693, 'f24': 694, \"'\": 695, 'side': 696, 'seam': 697, 'dplm': 698, 'hlmn': 699, 'tgpc': 700, 'pass': 701, '2x': 702, 'cyl': 703, 'apss': 704, 'ssps': 705, 'at': 706, '1.25': 707, 'dạng': 708, '11,25': 709, 'tối_đa': 710, 't148i5': 711, 'rcm': 712, 'vẫn': 713, 'giữ': 714, 'tồn_kho': 715, 'đặt_hàng': 716, 'ý_tưởng': 717, 'ae9': 718, 'pr': 719, '341149': 720, 'gp175895': 721}\n",
            "721\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "en_tokenizer = Tokenizer()\n",
        "en_tokenizer.fit_on_texts(en_input_tokenize)\n",
        "en_vocabulary = en_tokenizer.word_index\n",
        "en_size = len(en_vocabulary)\n",
        "print(en_vocabulary)\n",
        "print(en_size) # number of words in the vocabulary\n",
        "\n",
        "vi_tokenizer = Tokenizer()\n",
        "vi_tokenizer.fit_on_texts(vi_input_tokenize)\n",
        "vi_vocabulary = vi_tokenizer.word_index\n",
        "vi_size = len(vi_vocabulary)\n",
        "print(vi_vocabulary)\n",
        "print(vi_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vi_vocabulary[\"email\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN0OGxMz_Nwj",
        "outputId": "ca312607-bb9f-4639-ffc4-2feb71e8a362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u10srObYRib",
        "outputId": "382ed995-efab-457d-c49c-8861118d48bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: '<bos>', 2: '<eos>', 3: '\"', 4: 'to', 5: '.', 6: 'for', 7: '-', 8: 'updated', 9: 'width', 10: 'version', 11: 'fly', 12: ')', 13: 'added', 14: 'by', 15: '(', 16: ',', 17: 'and', 18: 'new', 19: 'opening', 20: 'marker', 21: 'from', 22: 'email', 23: 'of', 24: 'mfg', 25: 'panel', 26: 'spec', 27: '/', 28: 'hem', 29: 'at', 30: 'as', 31: 'pattern', 32: 'adding', 33: 'plant', 34: 'length', 35: 'waist', 36: '&', 37: 'change', 38: 'cut', 39: 'front', 40: 'the', 41: 'requested', 42: 'fabric', 43: 'garment', 44: 'update', 45: 'reduce', 46: '+', 47: '”', 48: ';', 49: 'measurement', 50: 'back', 51: 'id', 52: 'routing', 53: 'previous', 54: 'again', 55: 'previously', 56: 'it', 57: 'was', 58: 'following', 59: 'half', 60: 'leg', 61: 'binding', 62: 'on', 63: 'cost', 64: 'top', 65: '“', 66: 'color', 67: 'inner', 68: 'down', 69: 'add', 70: 'seam', 71: 'sling', 72: 'sew', 73: 'saving', 74: 'additional', 75: 'in', 76: 'pom', 77: '5', 78: 'usage', 79: 'bai', 80: 'bottom', 81: 'code', 82: 'size', 83: 'label', 84: 'position', 85: 'phu', 86: 'reduced', 87: 'thread', 88: 'project', 89: 'waistband', 90: 'edge', 91: 'page', 92: 'flatseam', 93: 'details', 94: 'fgm', 95: 'side', 96: 'style', 97: 'height', 98: 'outer', 99: 'please', 100: 'refer', 101: 'site', 102: 'use', 103: 'create', 104: 'task', 105: 'rise', 106: 'base', 107: 'dcr', 108: 'renamed', 109: '–', 110: '-inner', 111: 'elastic', 112: 'with', 113: 'information', 114: 'alt', 115: 'construction', 116: 'bom', 117: 'see', 118: 'a', 119: 'colorway', 120: 'addition', 121: 'product', 122: '1', 123: 'trim', 124: '2', 125: '3', 126: 'all', 127: 'mfgs', 128: 'move', 129: 'overedge', 130: 'sourced', 131: 'layout', 132: 'ver', 133: 'print', 134: '12', 135: 'tolerance', 136: 'up', 137: 'hung', 138: 'yen', 139: 'bind', 140: 'inside', 141: 'panels', 142: 'set', 143: 'plants', 144: 'baxa', 145: 'based', 146: 'ref', 147: 'overlap', 148: 'pouch', 149: 'placement', 150: 'part', 151: '8', 152: '10', 153: 'image', 154: '54', 155: 'd', 156: 'operation', 157: ':', 158: 'updating', 159: 'across', 160: '5s', 161: '16', 162: 'changing', 163: 'sleeve', 164: 'reduction', 165: 'gusset', 166: '58', 167: 'name', 168: 'type', 169: 'extended', 170: '7', 171: 'meas', 172: 'h5', 173: 'm', 174: 'trimoff', 175: '1/4', 176: 'request', 177: 'follow', 178: 'tack', 179: 'crotch', 180: 'attach', 181: 'sweep', 182: 'neck', 183: 'only', 184: 'no', 185: '2023', 186: 'styles', 187: 'i', 188: '60', 189: 'je2c59', 190: '3/16', 191: 'or', 192: '#', 193: 'min', 194: '6', 195: '4', 196: 'inseam', 197: 'finished', 198: 't148', 199: 't148h3', 200: 't148h3xl', 201: '2021', 202: '1/8', 203: '78', 204: 's22', 205: 's3', 206: 'data', 207: '87ss', 208: 'solid', 209: 'needle', 210: 'outside', 211: 'wb', 212: 'thpu', 213: '90', 214: 'shoulder', 215: 'hw3u', 216: 'savings', 217: 'changed', 218: 'using', 219: 'tolerances', 220: 'one', 221: 'be', 222: 'h2', 223: 'h3', 224: 'h4', 225: 'h6', 226: 'h7', 227: 'h8', 228: 'h81', 229: 'h82', 230: 'h83', 231: 'alternate', 232: 'pieces', 233: 'spi', 234: 'cf', 235: 'prf859', 236: '320', 237: 'layer', 238: 'description', 239: 'make', 240: 'date', 241: 'administrator', 242: 'general', 243: 'attributes', 244: 'hip', 245: 'seat', 246: 'folded', 247: 'total', 248: 'outseam', 249: 't148h5', 250: 'account', 251: '3/4', 252: '14', 253: '87hh', 254: '87sh', 255: '87hs', 256: '87ds', 257: 'stitch', 258: 'allowance', 259: 'exposed', 260: 'h', 261: 'spsa', 262: 'trom', 263: 'rtds', 264: 'kj', 265: 'pmeas', 266: 'per', 267: 'cyl', 268: 'basa', 269: 'due', 270: 'straight', 271: 'e', 272: '67/65', 273: 'ad025d1;change', 274: '62/59', 275: 'ad025d6', 276: 'corners', 277: 'c2', 278: 'seams', 279: 'separate', 280: 'direction', 281: 'wide', 282: 'shrinkage', 283: 'skewness', 284: 'improvement(reduce', 285: 'lenght', 286: 'an', 287: 'average', 288: 'rate', 289: 'colors', 290: 'changes', 291: 'layers', 292: 'mobilon', 293: 'c', 294: 't18', 295: \"'s\", 296: 'fiber', 297: 'content', 298: 'piece', 299: 'buy', 300: 'knit', 301: 'designer', 302: 'method', 303: 'active', 304: 'manager', 305: 'issued', 306: 'trunk', 307: 'flat', 308: 't148h4', 309: 't148h3l', 310: '20', 311: '21', 312: '95', 313: '9', 314: '2022', 315: 't148h.', 316: '1/3', 317: '13', 318: '15', 319: '28', 320: '79', 321: 'pgu', 322: 'img', 323: '002', 324: '11', 325: 'sewing', 326: 'gauge', 327: 'visibility', 328: 'looper', 329: 'latch', 330: 'circular', 331: 'another', 332: '3/8&quot', 333: 'break', 334: 'open', 335: 'gp', 336: '2e', 337: '2p', 338: '8b', 339: 'mbtd', 340: 'removed', 341: '106a', 342: 'elcatex', 343: 'ash', 344: 'gray', 345: 'eku', 346: 'hlhn', 347: 'tsu', 348: 'honduras', 349: 'dc', 350: 'g4', 351: 'bust', 352: 'chest', 353: '-(half', 354: 'armhole', 355: 'sides', 356: 'tubular', 357: 'dart', 358: 'wf', 359: 'needed', 360: '32', 361: 's', 362: 'elsal', 363: 'g', 364: '504', 365: 'drop', 366: 'mitered', 367: 'ad025d8', 368: 'ad025d9', 369: 'ad025d5,d6,d7', 370: 'way', 371: 'cutting', 372: 'printed', 373: 'fabrics', 374: 'must', 375: 'sewn', 376: 'same', 377: 'minimize', 378: 'torquing', 379: 'directional', 380: 'prints', 381: 'is', 382: 'internal', 383: 'gm', 384: 'aps', 385: 'h.', 386: '13.25', 387: '13.5', 388: 'i2', 389: '1/42', 390: '13.252', 391: '13.52', 392: 'i3', 393: '1/43', 394: '13.253', 395: '13.53', 396: 'i4', 397: '1/44', 398: '13.254', 399: '13.54', 400: 'i5', 401: '1/45', 402: '13.255', 403: '13.55', 404: 'i6', 405: '1/46', 406: '13.256', 407: '13.56', 408: 'i7', 409: '1/47', 410: '13.257', 411: '13.57', 412: 'i8', 413: '1/48', 414: '13.258', 415: '13.58', 416: 'i81', 417: '1/481', 418: '13.1', 419: '13.11', 420: 'i82', 421: '1/482', 422: '13.2', 423: '13.22', 424: 'i83', 425: '1/483', 426: '13.3', 427: '13.33', 428: 't148i2', 429: 'rbw649', 430: '35.5', 431: 't148i1', 432: 't148i3', 433: 't148i4', 434: '3.42', 435: '%', 436: 'mops', 437: 'load', 438: 's23', 439: 'used', 440: 'ae923a4', 441: 'ae923a5', 442: 'how', 443: 'measure', 444: 'more', 445: 'any', 446: 'other', 447: 'ae924a1', 448: 'ae924a2', 449: 'rev', 450: '8gg', 451: 'replace', 452: 'center', 453: 'horizontally', 454: 'vertically', 455: 'assembly', 456: '1/2', 457: 'this', 458: 's21', 459: 'cold', 460: 'water', 461: 't0351a', 462: 't0351b', 463: 'sizes', 464: 'ad025a', 465: 'b', 466: 'hlsn', 467: '01', 468: 'prw649', 469: '70', 470: 'prw651', 471: '72', 472: 'material', 473: 'divison', 474: 'primary', 475: 'manufactured', 476: 'manf', 477: 'comments', 478: 'last', 479: 'edited', 480: 'modified', 481: 'imperfect', 482: 'irregular', 483: 'technical', 484: 'brand', 485: 'specification', 486: 'hbi', 487: 'division', 488: '63', 489: 'idion', 490: '9kkk', 491: 't1', 492: 'th5', 493: '8h3l', 494: '221', 495: '955', 496: '995', 497: '222', 498: 't14', 499: '22', 500: 't8h.', 501: '202', 502: '204', 503: '148h4', 504: '205', 505: '148h5', 506: '206', 507: '148h6', 508: '207', 509: '148h7', 510: '208', 511: '148h8', 512: '134', 513: '135', 514: '136', 515: '137', 516: '138', 517: '7/8', 518: '18', 519: '67', 520: '34', 521: '84', 522: '44', 523: '85', 524: '45', 525: '86', 526: '46', 527: '53', 528: '25', 529: '76', 530: '26', 531: '77', 532: '3/41', 533: '55', 534: '27', 535: '3/42', 536: '56', 537: '3/43', 538: '57', 539: '29', 540: '3/44', 541: 's89', 542: 'pguimg', 543: '22s', 544: 'pgug', 545: '45s', 546: 'surin', 547: 'yun', 548: 'white', 549: 'y00', 550: 'yu2', 551: 'yunwhite', 552: 'yun002', 553: 'r', 554: '92', 555: '96', 556: '3432', 557: '344', 558: '3r3r', 559: '343', 560: 'rc2', 561: '11s', 562: '33', 563: 'type/', 564: 'item', 565: 'descrn', 566: 'coverstitch', 567: '87663', 568: 'mens', 569: 'boxer', 570: 'brief', 571: 'expwb', 572: '12/07/2023', 573: 'strap', 574: 'heigh', 575: 'non', 576: 'parts', 577: 'neckline', 578: 'armholes', 579: 'shoulders', 580: 'blind', 581: 'chainoffs', 582: 'fro', 583: 'k', 584: '8q', 585: 'option', 586: 'el', 587: 'salvador', 588: '3,4,5,6', 589: 'l', 590: '5,6', 591: 'cylinder', 592: '17', 593: '3764lw', 594: '30', 595: 'f', 596: 'hps', 597: 'pane', 598: 'collar', 599: 'cbn', 600: 'upper', 601: 'slope', 602: 'coincide', 603: 'current', 604: '<', 605: '23', 606: '100', 607: 'spread', 608: 'allowed', 609: 'two', 610: 'plies', 611: 'ad025a8', 612: 'include', 613: 'note', 614: 'about', 615: 'accepted', 616: 'sca', 617: '303381', 618: '303804', 619: 'fold', 620: 'contour', 621: 's25', 622: 'aqop', 623: 'h9c', 624: 'mobh', 625: '@877853', 626: 's24', 627: 'ruf', 628: 'mobs', 629: 'augu', 630: '@240322', 631: 'ae590c1;ae590c2;ae590c3', 632: 'ae590a3', 633: 'bhc', 634: '330101', 635: 'f22', 636: '314561', 637: 'facing', 638: 'seaming', 639: 'where', 640: '607', 641: 'not', 642: 'available', 643: 'capacity', 644: 'requires', 645: 'prior', 646: 'approval', 647: '338242', 648: 'urban', 649: 'outfitters', 650: '8i2', 651: 'r148i4', 652: '341150', 653: 'gp174922', 654: 'bag', 655: 'out', 656: 'assemble', 657: 'together', 658: 'hidden', 659: 'along', 660: 'through', 661: 'staystitch', 662: 'notch', 663: 'care', 664: '298191', 665: 'pi', 666: 'myfit', 667: 'addtion', 668: 't0351b7', 669: 'tx2f81', 670: 'improvement', 671: 'operations', 672: '277761', 673: '277762', 674: '277763', 675: '277764', 676: '277765', 677: 'f20', 678: '261897', 679: '1new', 680: 'tnw', 681: 'team', 682: 'wash', 683: 'pad', 684: 'stamp', 685: '57c', 686: '38p-', 687: 'spandex', 688: '19', 689: 'if', 690: 'becomes', 691: 'sp20', 692: 'g414', 693: 'purchased', 694: '1xe', 695: 'ukb', 696: 'tm0', 697: 'pxf', 698: 'hcu', 699: '5su', 700: 'vyu', 701: 'wash.', 702: 'remove', 703: 'uses', 704: 'incremented', 705: 's20', 706: 'ad025c.', 707: 'miter', 708: 't24st', 709: 'ud5c', 710: '259701', 711: 't24', 712: 'production', 713: 'reverted', 714: 'royalty', 715: 'blue', 716: 't', 717: 'mnh', 718: 'trademark', 719: 'f24', 720: 'mfg\"s', 721: 'assortment', 722: 'dplm', 723: 'cylinders', 724: 'hlmn', 725: 'tgpc', 726: 'pass', 727: 's-2x', 728: 'apss', 729: 'ssps', 730: 'created', 731: '1.25', 732: 'form', 733: '11.25', 734: 'max', 735: 't148i5', 736: 'rcm', 737: 'still', 738: 'keep', 739: 'factory', 740: 'inventory', 741: 'has', 742: 'been', 743: 'order', 744: 'idea', 745: '4/5', 746: 'ae9', 747: 'pr', 748: '341149', 749: 'gp175895', 0: ''}\n",
            "{1: '<bos>', 2: '<eos>', 3: '\"', 4: '.', 5: 'cập_nhật', 6: 'chiều', 7: 'thêm', 8: '-', 9: 'được', 10: '/', 11: 'cho', 12: 'rộng', 13: 'phiên_bản', 14: 'túi', 15: 'trước', 16: '(', 17: ')', 18: 'đã', 19: 'lên', 20: 'miệng', 21: 'theo', 22: 'và', 23: 'bên', 24: ',', 25: 'rập', 26: 'mới', 27: 'giảm', 28: 'từ', 29: 'trong', 30: 'email', 31: 'đường', 32: 'mảnh', 33: 'thông_số', 34: 'mở', 35: 'thay_đổi', 36: 'mfg', 37: 'may', 38: 'của', 39: 'kỹ_thuật', 40: '1', 41: 'viền', 42: 'độ', 43: 'để', 44: 'cắt', 45: 'trên', 46: 'dài', 47: 'ở', 48: 'phía', 49: 'đi', 50: 'vào', 51: 'nhà_máy', 52: 'yêu_cầu', 53: 'qua', 54: 'đó', 55: 'xuống', 56: 'sử_dụng', 57: 'màu', 58: 'vải', 59: '&', 60: 'lưng', 61: 'một', 62: ';', 63: 'các', 64: '”', 65: 'mẫu', 66: 'bổ_sung', 67: 'dây', 68: 'id', 69: '+', 70: 'là', 71: 'may_mặc', 72: 'số_đo', 73: '3', 74: 'định_tuyến', 75: 'trang', 76: 'thành', 77: 'có', 78: 'lại', 79: 'đùi', 80: 'tiết_kiệm', 81: 'chi_phí', 82: 'biết', 83: '“', 84: 'vị_trí', 85: 'nửa', 86: 'hàng', 87: 'ngoài', 88: 'chỉ', 89: 'thắt_lưng', 90: 'sau', 91: 'bìa', 92: 'cách', 93: 'tham_khảo', 94: 'phần', 95: 'kiểu', 96: 'pom', 97: 'kích_thước', 98: 'tên', 99: 'đeo', 100: 'mã', 101: '5', 102: 'bài', 103: 'nhãn', 104: '4', 105: '8', 106: 'phú', 107: 'dự_án', 108: 'cao', 109: 'cạnh', 110: 'phẳng', 111: 'chi_tiết', 112: 'fgm', 113: 'tạo', 114: 'dựa', 115: 'in', 116: 'dung_sai', 117: 'vui_lòng', 118: 'dưới', 119: 'mặt', 120: '16', 121: '2', 122: 'dcr', 123: 'mở_miệng', 124: 'đổi', 125: '–', 126: 'thông_tin', 127: 'alt', 128: 'bom', 129: 'nhà_máy_may', 130: 'về', 131: 'ràng_buộc', 132: 'xem', 133: 'nhiệm_vụ', 134: 'không', 135: '12', 136: 'tất_cả', 137: 'mfgs', 138: 'di_chuyển', 139: 'vắt_sổ', 140: 'đáy', 141: 'nguồn_gốc', 142: 'bố_cục', 143: 'lớp', 144: 'loại', 145: 'hưng_yên', 146: 'cùng', 147: 'cổ', 148: 'baxa', 149: 'với', 150: 'miếng', 151: 'sản_phẩm', 152: 'hoạt_động', 153: 'nâng', 154: '10', 155: '54', 156: 'd', 157: 'tấm', 158: ':', 159: '2023', 160: '5s', 161: 'tay_áo', 162: 'lót', 163: 'thay_thế', 164: '58', 165: 'chồng_chéo', 166: 'sản_xuất', 167: 'mở_rộng', 168: '7', 169: 'h5', 170: 'đế', 171: 'dự_phòng', 172: 'bớt', 173: 'khâu', 174: 'thun', 175: 'quần', 176: 'gắn', 177: 'đặt', 178: 'h', 179: 'vai', 180: 's', 181: 'ver', 182: 'mô_hình', 183: 'i', 184: '60', 185: 'je2c59', 186: 'hoặc', 187: 'ngày', 188: 'tối_thiểu', 189: 'nữa', 190: 'gập', 191: 'đóng', 192: 'ảnh', 193: 'thành_phẩm', 194: 't148', 195: 't148h3m', 196: '2021', 197: '67', 198: '44', 199: '78', 200: 's22', 201: 's3', 202: 'dữ_liệu', 203: '87ss', 204: 'đo', 205: 'trơn', 206: 'kim', 207: 'bằng', 208: 'khác', 209: 'wb', 210: 'thpu', 211: '\\u200b', 212: '90', 213: 'hw3u', 214: 'góc', 215: 'hướng', 216: 'h2', 217: 'h3', 218: 'h4', 219: 'h6', 220: 'h7', 221: 'h8', 222: 'h81', 223: 'h82', 224: 'h83', 225: 'spi', 226: 'cf', 227: 'prf859', 228: '320', 229: 'làm', 230: 'mua', 231: 'quản_trị', 232: 'viên', 233: '#', 234: 'thuộc_tính', 235: 'chung', 236: 'tăng', 237: '6', 238: 'hông', 239: 'ghế', 240: 'tổng_cộng', 241: 'cắt_xén', 242: 't148h5', 243: 't148h3xl', 244: 'tính', 245: '14', 246: '45', 247: '46', 248: '42', 249: '43', 250: '87hh', 251: '87sh', 252: '87hs', 253: '87ds', 254: 'thao_tác', 255: 'mô_tả', 256: 'dây_thun', 257: 'hở', 258: 'đang', 259: 'spsa', 260: 'quét', 261: 'dán', 262: 'trom', 263: 'rtds', 264: 'kj', 265: 'cần', 266: 'pmeas', 267: 'trụ', 268: 'basa', 269: 'sang', 270: 'do', 271: 'thẳng', 272: 'phiên_bản_mẫu', 273: 'cấu_trúc', 274: 'e', 275: '65', 276: 'ad025d1', 277: '62', 278: '59', 279: 'ad025d6', 280: 'c2', 281: 'new', 282: 'wide', 283: 'cải_thiện', 284: 'co', 285: 'lệch', 286: 'tỷ_lệ', 287: 'trung_bình', 288: 'xây_dựng', 289: 'lắp_ráp', 290: 'mobilon', 291: 'dọc', 292: 'c', 293: 't18', 294: 'đến', 295: 'sợi', 296: 'bộ_phận', 297: 'sự', 298: 'nhà', 299: 'thiết_kế', 300: 'phương_pháp', 301: 'thi_công', 302: 'giám_đốc', 303: 'phát_hành', 304: 'thân', 305: 'bằng_phẳng', 306: 'hoàn_thành', 307: 't148h4', 308: 't148h3l', 309: '20', 310: '21', 311: '95', 312: '9', 313: '2022', 314: 't148h', 315: '13', 316: '15', 317: '28', 318: '79', 319: 'pgu', 320: 'img', 321: '002', 322: '11', 323: 'mũi', 324: 'phân_chia', 325: 'tầm', 326: 'nhìn', 327: 'looper', 328: 'chốt', 329: 'cài', 330: 'tới', 331: 'tròn', 332: 'quot', 333: 'đàn_hồi', 334: 'gp', 335: '2e', 336: '2p', 337: '8b', 338: 'mbtd', 339: 'xóa_quét', 340: '106a', 341: 'elcatex', 342: 'ash', 343: 'grey', 344: 'eku', 345: 'hlhn', 346: 'tsu', 347: 'honduras', 348: 'dc', 349: 'g4', 350: 'bán_thân', 351: 'ngực', 352: 'armhole', 353: 'ống', 354: 'áo', 355: 'phi_tiêu', 356: 'cây', 357: 'wf', 358: '32', 359: 'elsal', 360: '504', 361: 'thả', 362: 'hình_ảnh', 363: 'liên_kết', 364: 'nhẹ', 365: 'ad025d8', 366: 'ad025d9', 367: 'ad025d5', 368: 'd6', 369: 'd7', 370: 'thiết_lập', 371: 'một_chiều', 372: 'phép', 373: 'nối', 374: 'hai', 375: 'phải', 376: 'giảm_thiểu', 377: 'lực', 378: 'xoắn', 379: 'bản', 380: 'đối_với', 381: 'mỗi', 382: 'tác', 383: 'vụ', 384: 'gm', 385: 'aps', 386: '13,25', 387: '13,5', 388: 'i2', 389: '13,252', 390: '13,52', 391: 'i3', 392: '13,253', 393: '13,53', 394: 'i4', 395: '13,254', 396: '13,54', 397: 'i5', 398: '13,255', 399: '13,55', 400: 'i6', 401: '13,256', 402: '13,56', 403: 'i7', 404: '47', 405: '13,257', 406: '13,57', 407: 'i8', 408: '48', 409: '13,258', 410: '13,58', 411: 'i81', 412: '481', 413: '13,1', 414: '13,11', 415: 'i82', 416: '482', 417: '13,2', 418: '13,22', 419: 'i83', 420: '483', 421: '13,3', 422: '13,33', 423: 't148i2', 424: 'rbw649', 425: '35.5', 426: 't148i1', 427: 't148i3', 428: 't148i4', 429: '3,42', 430: '%', 431: 'mops', 432: '@', 433: 'tải', 434: 's23', 435: 'tại', 436: 'ae923a4', 437: 'ae923a5', 438: 'bất_kỳ', 439: 'nào', 440: 'ae924a1', 441: 'ae924a2', 442: 'rev', 443: '8gg', 444: 'giữa', 445: 'riêng_biệt', 446: 'nhau', 447: 'ngang', 448: 'cánh', 449: 'này', 450: 's21', 451: 'giặt', 452: 'nước_lạnh', 453: 't0351a', 454: 't0351b', 455: 'mức', 456: 'ad025a', 457: 'b', 458: 'a', 459: 'hlsn', 460: '01', 461: 'prw649', 462: '70', 463: 'prw651', 464: '72', 465: 'nội_dung', 466: 'vật_liệu', 467: 'miêu_tả', 468: 'sơ_đẳng', 469: 'đan', 470: 'bình_luận', 471: 'chỉnh_sửa', 472: 'lần', 473: 'cuối', 474: 'bởi', 475: 'sửa_đổi', 476: 'hoàn_hảo', 477: 'độc_đáo', 478: 'thương_hiệu', 479: 'đặc_điểm', 480: 'hbi', 481: '63', 482: 'idion', 483: '9kkk', 484: 't1', 485: 'th5', 486: '8h3l', 487: '221', 488: '955', 489: '995', 490: '222', 491: 't14', 492: '22', 493: 't8h', 494: '202', 495: '204', 496: '148h4', 497: '205', 498: '148h5', 499: '206', 500: '148h6', 501: '207', 502: '148h7', 503: '208', 504: '148h8', 505: '134', 506: '135', 507: '136', 508: '137', 509: '138', 510: '18', 511: '34', 512: '84', 513: '85', 514: '86', 515: '53', 516: '25', 517: '76', 518: '26', 519: '77', 520: '41', 521: '55', 522: '27', 523: '56', 524: '57', 525: '29', 526: 's89', 527: 'pguimg', 528: '22s', 529: 'pgug', 530: '45s', 531: 'surin', 532: 'cut', 533: 'sew', 534: 'yun', 535: 'trắng', 536: 'y00', 537: 'yu2', 538: 'yunwhite', 539: 'yun002', 540: 'r', 541: '92', 542: '96', 543: '3432', 544: '344', 545: '3r3r', 546: '343', 547: 'rc2', 548: '11s', 549: '33', 550: 'mặt_hàng', 551: 'ngắt', 552: '87663', 553: 'mens', 554: 'knit', 555: 'boxer', 556: 'brief', 557: 'expwb', 558: 'mẫu_số', 559: '07', 560: 'mặt_đường', 561: 'dành', 562: 'hình', 563: 'nách', 564: 'mù', 565: 'dây_xích', 566: 'quần_áo', 567: '7k', 568: '8q', 569: 'tùy', 570: 'chọn', 571: 'el', 572: 'salvador', 573: '3,4,5,6', 574: 'l', 575: 'm', 576: '5,6', 577: 'thay', 578: 'xi_lanh', 579: '17', 580: '3764lw', 581: '30', 582: 'f', 583: 'g', 584: 'hps', 585: 'break', 586: 'qua_mặt', 587: 'cbn', 588: 'dốc', 589: 'công_trình', 590: 'trùng', 591: 'hiện_tại', 592: '<', 593: '23', 594: '100', 595: 'lây_lan', 596: 'tách', 597: 'ad025a8', 598: 'bao_gồm', 599: 'ghi_chú', 600: 'định_hướng', 601: 'chấp_nhận', 602: 'sca', 603: '303381', 604: 'internal', 605: '303804', 606: 'nhô', 607: 's25', 608: 'aqop', 609: 'h9c', 610: 'mobh', 611: '877853', 612: 's24', 613: 'ruf', 614: 'mobs', 615: 'augu', 616: '240322', 617: 'ae590c1', 618: 'ae590c2', 619: 'ae590c3', 620: 'ae590a3', 621: '5g', 622: 'bhc', 623: '330101', 624: 'f22', 625: '314561', 626: 'khi', 627: '607', 628: 'sức_chứa', 629: 'phê_duyệt', 630: '338242', 631: 'urban', 632: 'outfitters', 633: '8i2', 634: 'r148i4', 635: '341150', 636: 'gp174922', 637: 'đóng_gói', 638: 'giấu', 639: 'xuyên', 640: 'chồng', 641: 'khía', 642: 'chăm_sóc', 643: 'họa', 644: 'tiết', 645: '298191', 646: 'pi', 647: 'myfit', 648: 't0351b7', 649: 'tx2f81', 650: 'cải_tiến', 651: 'tham_chiếu', 652: '277761', 653: '277762', 654: '277763', 655: '277764', 656: '277765', 657: 'f20', 658: '261897', 659: 'tnw', 660: 'nhóm', 661: 'tem', 662: 'pad', 663: 'hàm_lượng', 664: '57c', 665: '38p', 666: 'spandex', 667: '19', 668: 'nếu', 669: 'sp20', 670: 'g414', 671: 'nội_bộ', 672: '1xe', 673: 'ukb', 674: 'tm0', 675: 'pxf', 676: 'hcu', 677: '5su', 678: 'vyu', 679: 'xóa', 680: 's20', 681: 'ad025c', 682: 'vát', 683: 't24st', 684: 'ud5c', 685: '259701', 686: 't24', 687: 'hoàn_nguyên', 688: 'royal', 689: 'blue', 690: '6t', 691: 'mnh', 692: 'nhãn_hiệu', 693: 'treo', 694: 'f24', 695: \"'\", 696: 'side', 697: 'seam', 698: 'dplm', 699: 'hlmn', 700: 'tgpc', 701: 'pass', 702: '2x', 703: 'cyl', 704: 'apss', 705: 'ssps', 706: 'at', 707: '1.25', 708: 'dạng', 709: '11,25', 710: 'tối_đa', 711: 't148i5', 712: 'rcm', 713: 'vẫn', 714: 'giữ', 715: 'tồn_kho', 716: 'đặt_hàng', 717: 'ý_tưởng', 718: 'ae9', 719: 'pr', 720: '341149', 721: 'gp175895', 0: ''}\n"
          ]
        }
      ],
      "source": [
        "en_vocabulary_reverse = {}\n",
        "for key, value in en_tokenizer.word_index.items():\n",
        "  en_vocabulary_reverse[value] = key\n",
        "en_vocabulary_reverse[0] = ''\n",
        "\n",
        "vi_vocabulary_reverse = {}\n",
        "for key, value in vi_tokenizer.word_index.items():\n",
        "  vi_vocabulary_reverse[value] = key\n",
        "vi_vocabulary_reverse[0] = ''\n",
        "\n",
        "print(en_vocabulary_reverse)\n",
        "print(vi_vocabulary_reverse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZHFF35jwTLQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/hbi/dictionary_en.pkl', 'wb') as f:\n",
        "    pickle.dump(en_vocabulary, f)\n",
        "with open('/content/drive/MyDrive/hbi/dictionary_vi.pkl', 'wb') as f:\n",
        "    pickle.dump(vi_vocabulary, f)\n",
        "with open('/content/drive/MyDrive/hbi/dictionary_vi_reverse.pkl', 'wb') as f:\n",
        "    pickle.dump(vi_vocabulary_reverse, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1XRhjP_YTLO",
        "outputId": "564113ae-f1fe-4ae6-9ad2-d186754f685d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 43  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[ 1 71  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "en_sequence = en_tokenizer.texts_to_sequences(en_input_tokenize)\n",
        "enmaxlen = max([len(i) for i in en_sequence])\n",
        "en_sequence = pad_sequences(en_sequence, maxlen = enmaxlen, padding = 'post')\n",
        "print(en_sequence[0])\n",
        "\n",
        "vi_sequence = vi_tokenizer.texts_to_sequences(vi_input_tokenize)\n",
        "vimaxlen = max([len(i) for i in vi_sequence])\n",
        "vi_sequence = pad_sequences(vi_sequence, maxlen = vimaxlen, padding = 'post')\n",
        "print(vi_sequence[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBkz2WErgX0S",
        "outputId": "2c17753a-415a-43e6-b1e6-7ec996be8972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "54\n"
          ]
        }
      ],
      "source": [
        "print(en_sequence.shape[1])\n",
        "print(vi_sequence.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO8lfPR6YVdS"
      },
      "outputs": [],
      "source": [
        "split_ratio = 0.8\n",
        "split = round(len(vi_sequence)* split_ratio)\n",
        "\n",
        "trainX = en_sequence[:split]\n",
        "testX = en_sequence[split:]\n",
        "trainY = vi_sequence[:split]\n",
        "testY = vi_sequence[split:]\n",
        "\n",
        "train_samples = len(trainX)\n",
        "val_samples = len(testX)\n",
        "batch_size = 32\n",
        "epochs = 400\n",
        "latent_dim=128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmwHrsIVYV1e"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X, y, batch_size):\n",
        "  while True:\n",
        "    for j in range(0, len(X), batch_size):\n",
        "      encoder_input_data = []\n",
        "      decoder_input_data = []\n",
        "      decoder_target_data = []\n",
        "      for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "        encoder_input_data.append(input_text)\n",
        "        decoder_input_data.append(target_text)\n",
        "        decodertargetdata = to_categorical(target_text, num_classes=vi_size+1)[1:]\n",
        "        decoder_target_data.append(np.concatenate((np.array(decodertargetdata), np.zeros((1, vi_size+1))), axis = 0))\n",
        "      encoder_input_data = np.array(encoder_input_data)\n",
        "      decoder_input_data = np.array(decoder_input_data)\n",
        "      decoder_target_data = np.array(decoder_target_data)\n",
        "      yield([encoder_input_data, decoder_input_data], decoder_target_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fYRV-e4JOi"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxGDKaYdYXhm"
      },
      "outputs": [],
      "source": [
        "# Define an input sequence and process it.\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import re\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(en_size+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-HNO5t6ag9B"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(vi_size+1, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vi_size+1, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(X, y):\n",
        "  encoder_input_data = []\n",
        "  decoder_input_data = []\n",
        "  decoder_target_data = []\n",
        "  for i, (input_text, target_text) in enumerate(zip(X, y)):\n",
        "    encoder_input_data.append(input_text)\n",
        "    decoder_input_data.append(target_text)\n",
        "    decodertargetdata = to_categorical(target_text, num_classes=vi_size+1)[1:]\n",
        "    decoder_target_data.append(np.concatenate((np.array(decodertargetdata), np.zeros((1, vi_size+1))), axis = 0))\n",
        "  encoder_input_data = np.array(encoder_input_data)\n",
        "  decoder_input_data = np.array(decoder_input_data)\n",
        "  decoder_target_data = np.array(decoder_target_data)\n",
        "  return [encoder_input_data, decoder_input_data], decoder_target_data"
      ],
      "metadata": {
        "id": "ThJ2Cb0MAoJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, target_train = generate_batch(trainX, trainY)\n",
        "data_test, target_test = generate_batch(testX, testY)"
      ],
      "metadata": {
        "id": "eDhVlqwDJ3lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.003),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history=model.fit(data_train, target_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(data_test, target_test),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    validation_steps = val_samples//batch_size,\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Kq7EYzhr-aIu",
        "outputId": "01ffe632-1e70-421a-8aab-9ee17b391350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m96,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m92,416\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m131,584\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]     │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),    │        \u001b[38;5;34m131,584\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m722\u001b[0m)      │         \u001b[38;5;34m93,138\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">92,416</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]     │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">722</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">93,138</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m544,722\u001b[0m (2.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544,722</span> (2.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m544,722\u001b[0m (2.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544,722</span> (2.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - acc: 0.2068 - loss: 6.3762 - val_acc: 0.7172 - val_loss: 5.2246\n",
            "Epoch 2/400\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - acc: 0.7094 - loss: 5.5501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.7094 - loss: 5.5501 - val_acc: 0.0370 - val_loss: 5.7097\n",
            "Epoch 3/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - acc: 0.1551 - loss: 5.2462 - val_acc: 0.7211 - val_loss: 5.0324\n",
            "Epoch 4/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.7464 - loss: 4.9433 - val_acc: 0.0370 - val_loss: 5.7763\n",
            "Epoch 5/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - acc: 0.1195 - loss: 5.0272 - val_acc: 0.0403 - val_loss: 4.8480\n",
            "Epoch 6/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.0427 - loss: 4.6593 - val_acc: 0.0370 - val_loss: 5.3354\n",
            "Epoch 7/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - acc: 0.0407 - loss: 4.8335 - val_acc: 0.0422 - val_loss: 4.7250\n",
            "Epoch 8/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.0413 - loss: 4.5986 - val_acc: 0.0370 - val_loss: 5.2041\n",
            "Epoch 9/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - acc: 0.0415 - loss: 4.6887 - val_acc: 0.0552 - val_loss: 4.6404\n",
            "Epoch 10/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - acc: 0.0513 - loss: 4.5464 - val_acc: 0.0370 - val_loss: 5.3029\n",
            "Epoch 11/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - acc: 0.0439 - loss: 4.5715 - val_acc: 0.0476 - val_loss: 4.5525\n",
            "Epoch 12/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.0413 - loss: 4.4168 - val_acc: 0.0370 - val_loss: 5.2014\n",
            "Epoch 13/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 246ms/step - acc: 0.0457 - loss: 4.5330 - val_acc: 0.0548 - val_loss: 4.4585\n",
            "Epoch 14/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.0427 - loss: 4.1633 - val_acc: 0.0370 - val_loss: 5.3643\n",
            "Epoch 15/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 348ms/step - acc: 0.0471 - loss: 4.3652 - val_acc: 0.0625 - val_loss: 4.3483\n",
            "Epoch 16/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - acc: 0.0442 - loss: 4.2377 - val_acc: 0.0432 - val_loss: 5.0665\n",
            "Epoch 17/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - acc: 0.0499 - loss: 4.2156 - val_acc: 0.0725 - val_loss: 4.2297\n",
            "Epoch 18/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.0499 - loss: 4.4891 - val_acc: 0.0309 - val_loss: 5.2062\n",
            "Epoch 19/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 242ms/step - acc: 0.0550 - loss: 4.0259 - val_acc: 0.0714 - val_loss: 4.1059\n",
            "Epoch 20/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.0641 - loss: 4.0833 - val_acc: 0.0309 - val_loss: 5.2897\n",
            "Epoch 21/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 369ms/step - acc: 0.0621 - loss: 3.9528 - val_acc: 0.0799 - val_loss: 4.0416\n",
            "Epoch 22/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - acc: 0.0427 - loss: 4.2030 - val_acc: 0.0309 - val_loss: 5.2550\n",
            "Epoch 23/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - acc: 0.0649 - loss: 3.8593 - val_acc: 0.0820 - val_loss: 3.9564\n",
            "Epoch 24/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.0598 - loss: 4.0357 - val_acc: 0.0370 - val_loss: 5.2363\n",
            "Epoch 25/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 445ms/step - acc: 0.0688 - loss: 3.6269 - val_acc: 0.0936 - val_loss: 3.8229\n",
            "Epoch 26/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.0527 - loss: 4.0314 - val_acc: 0.0370 - val_loss: 5.0126\n",
            "Epoch 27/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - acc: 0.0857 - loss: 3.4910 - val_acc: 0.1117 - val_loss: 3.6938\n",
            "Epoch 28/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.0726 - loss: 3.4752 - val_acc: 0.0370 - val_loss: 5.1267\n",
            "Epoch 29/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - acc: 0.0859 - loss: 3.4229 - val_acc: 0.1265 - val_loss: 3.6022\n",
            "Epoch 30/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.0798 - loss: 3.3922 - val_acc: 0.0309 - val_loss: 5.0213\n",
            "Epoch 31/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - acc: 0.0879 - loss: 3.3061 - val_acc: 0.1345 - val_loss: 3.4789\n",
            "Epoch 32/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1026 - loss: 3.0842 - val_acc: 0.0370 - val_loss: 5.0150\n",
            "Epoch 33/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - acc: 0.0971 - loss: 3.1875 - val_acc: 0.1343 - val_loss: 3.4163\n",
            "Epoch 34/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1040 - loss: 2.8168 - val_acc: 0.0370 - val_loss: 4.9284\n",
            "Epoch 35/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - acc: 0.1168 - loss: 2.9670 - val_acc: 0.1478 - val_loss: 3.2952\n",
            "Epoch 36/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.0670 - loss: 3.0571 - val_acc: 0.0370 - val_loss: 4.8697\n",
            "Epoch 37/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - acc: 0.1092 - loss: 2.8659 - val_acc: 0.1539 - val_loss: 3.2041\n",
            "Epoch 38/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1296 - loss: 3.0631 - val_acc: 0.0309 - val_loss: 4.9439\n",
            "Epoch 39/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 399ms/step - acc: 0.1239 - loss: 2.6213 - val_acc: 0.1595 - val_loss: 3.0960\n",
            "Epoch 40/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.0812 - loss: 3.4415 - val_acc: 0.0494 - val_loss: 4.9181\n",
            "Epoch 41/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - acc: 0.1161 - loss: 2.6187 - val_acc: 0.1541 - val_loss: 3.0358\n",
            "Epoch 42/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.1382 - loss: 2.5590 - val_acc: 0.0370 - val_loss: 4.7776\n",
            "Epoch 43/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - acc: 0.1324 - loss: 2.4992 - val_acc: 0.1638 - val_loss: 2.9661\n",
            "Epoch 44/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.0712 - loss: 2.7723 - val_acc: 0.0370 - val_loss: 5.0107\n",
            "Epoch 45/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 231ms/step - acc: 0.1360 - loss: 2.3689 - val_acc: 0.1634 - val_loss: 2.9222\n",
            "Epoch 46/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.0855 - loss: 3.3678 - val_acc: 0.0432 - val_loss: 4.8959\n",
            "Epoch 47/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - acc: 0.1319 - loss: 2.3243 - val_acc: 0.1672 - val_loss: 2.8209\n",
            "Epoch 48/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1339 - loss: 1.9563 - val_acc: 0.0370 - val_loss: 4.8874\n",
            "Epoch 49/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - acc: 0.1489 - loss: 2.1199 - val_acc: 0.1694 - val_loss: 2.7775\n",
            "Epoch 50/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - acc: 0.1211 - loss: 2.1567 - val_acc: 0.0370 - val_loss: 4.8034\n",
            "Epoch 51/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 458ms/step - acc: 0.1525 - loss: 2.0328 - val_acc: 0.1711 - val_loss: 2.7422\n",
            "Epoch 52/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.0969 - loss: 2.5819 - val_acc: 0.0370 - val_loss: 4.7227\n",
            "Epoch 53/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 386ms/step - acc: 0.1541 - loss: 1.9177 - val_acc: 0.1730 - val_loss: 2.6823\n",
            "Epoch 54/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1097 - loss: 2.1235 - val_acc: 0.0309 - val_loss: 4.6790\n",
            "Epoch 55/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.1647 - loss: 1.8107 - val_acc: 0.1759 - val_loss: 2.5991\n",
            "Epoch 56/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1011 - loss: 2.1987 - val_acc: 0.0432 - val_loss: 4.7107\n",
            "Epoch 57/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - acc: 0.1434 - loss: 1.9330 - val_acc: 0.1800 - val_loss: 2.5298\n",
            "Epoch 58/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.1966 - loss: 1.6035 - val_acc: 0.0432 - val_loss: 4.4327\n",
            "Epoch 59/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 396ms/step - acc: 0.1558 - loss: 1.8309 - val_acc: 0.1836 - val_loss: 2.5302\n",
            "Epoch 60/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2009 - loss: 1.2283 - val_acc: 0.0370 - val_loss: 4.6487\n",
            "Epoch 61/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - acc: 0.1650 - loss: 1.7570 - val_acc: 0.1867 - val_loss: 2.4154\n",
            "Epoch 62/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1068 - loss: 1.9552 - val_acc: 0.0494 - val_loss: 4.3971\n",
            "Epoch 63/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - acc: 0.1687 - loss: 1.6758 - val_acc: 0.1865 - val_loss: 2.4023\n",
            "Epoch 64/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.0912 - loss: 2.0077 - val_acc: 0.0370 - val_loss: 4.5710\n",
            "Epoch 65/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 444ms/step - acc: 0.1834 - loss: 1.4813 - val_acc: 0.1852 - val_loss: 2.4265\n",
            "Epoch 66/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - acc: 0.1752 - loss: 1.0768 - val_acc: 0.0370 - val_loss: 4.3748\n",
            "Epoch 67/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - acc: 0.1741 - loss: 1.4318 - val_acc: 0.1927 - val_loss: 2.3305\n",
            "Epoch 68/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.0983 - loss: 2.2653 - val_acc: 0.0494 - val_loss: 4.4470\n",
            "Epoch 69/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - acc: 0.1732 - loss: 1.4444 - val_acc: 0.1929 - val_loss: 2.2709\n",
            "Epoch 70/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2051 - loss: 1.3616 - val_acc: 0.0432 - val_loss: 4.2958\n",
            "Epoch 71/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - acc: 0.1742 - loss: 1.3663 - val_acc: 0.1956 - val_loss: 2.2383\n",
            "Epoch 72/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.1695 - loss: 0.9978 - val_acc: 0.0432 - val_loss: 4.3611\n",
            "Epoch 73/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - acc: 0.1788 - loss: 1.2735 - val_acc: 0.1979 - val_loss: 2.2038\n",
            "Epoch 74/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1838 - loss: 1.3640 - val_acc: 0.0494 - val_loss: 4.1918\n",
            "Epoch 75/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.1826 - loss: 1.2681 - val_acc: 0.2010 - val_loss: 2.1939\n",
            "Epoch 76/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.1937 - loss: 1.3472 - val_acc: 0.0432 - val_loss: 4.5109\n",
            "Epoch 77/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - acc: 0.1858 - loss: 1.1828 - val_acc: 0.2024 - val_loss: 2.1634\n",
            "Epoch 78/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2151 - loss: 1.1016 - val_acc: 0.0494 - val_loss: 4.1725\n",
            "Epoch 79/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - acc: 0.1853 - loss: 1.1398 - val_acc: 0.2033 - val_loss: 2.1181\n",
            "Epoch 80/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.1966 - loss: 1.5710 - val_acc: 0.0432 - val_loss: 4.3044\n",
            "Epoch 81/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - acc: 0.1737 - loss: 1.1200 - val_acc: 0.2004 - val_loss: 2.1299\n",
            "Epoch 82/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3134 - loss: 0.9653 - val_acc: 0.0494 - val_loss: 4.0947\n",
            "Epoch 83/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - acc: 0.1994 - loss: 1.0644 - val_acc: 0.2037 - val_loss: 2.0885\n",
            "Epoch 84/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.2236 - loss: 0.8201 - val_acc: 0.0556 - val_loss: 3.9974\n",
            "Epoch 85/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - acc: 0.1999 - loss: 1.0337 - val_acc: 0.2099 - val_loss: 2.0422\n",
            "Epoch 86/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1524 - loss: 0.7838 - val_acc: 0.0679 - val_loss: 4.0390\n",
            "Epoch 87/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - acc: 0.1872 - loss: 0.9994 - val_acc: 0.2099 - val_loss: 2.0267\n",
            "Epoch 88/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2251 - loss: 0.9405 - val_acc: 0.0494 - val_loss: 4.0652\n",
            "Epoch 89/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 432ms/step - acc: 0.2005 - loss: 0.8976 - val_acc: 0.2093 - val_loss: 2.0078\n",
            "Epoch 90/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2137 - loss: 0.8567 - val_acc: 0.0617 - val_loss: 3.8940\n",
            "Epoch 91/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - acc: 0.1968 - loss: 0.8919 - val_acc: 0.2135 - val_loss: 1.9767\n",
            "Epoch 92/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.3533 - loss: 0.6043 - val_acc: 0.0617 - val_loss: 3.8119\n",
            "Epoch 93/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - acc: 0.2150 - loss: 0.7981 - val_acc: 0.2110 - val_loss: 2.0148\n",
            "Epoch 94/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1325 - loss: 0.7941 - val_acc: 0.0741 - val_loss: 3.7193\n",
            "Epoch 95/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - acc: 0.1985 - loss: 0.8599 - val_acc: 0.2162 - val_loss: 1.9258\n",
            "Epoch 96/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2108 - loss: 0.6866 - val_acc: 0.0679 - val_loss: 3.8436\n",
            "Epoch 97/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - acc: 0.2099 - loss: 0.7691 - val_acc: 0.2182 - val_loss: 1.9258\n",
            "Epoch 98/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2293 - loss: 1.0302 - val_acc: 0.0679 - val_loss: 3.8886\n",
            "Epoch 99/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - acc: 0.2174 - loss: 0.7501 - val_acc: 0.2178 - val_loss: 1.8966\n",
            "Epoch 100/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2251 - loss: 0.9248 - val_acc: 0.0494 - val_loss: 3.7873\n",
            "Epoch 101/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - acc: 0.1959 - loss: 0.7779 - val_acc: 0.2203 - val_loss: 1.8891\n",
            "Epoch 102/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.3162 - loss: 0.9056 - val_acc: 0.0741 - val_loss: 3.7120\n",
            "Epoch 103/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - acc: 0.2124 - loss: 0.7197 - val_acc: 0.2197 - val_loss: 1.8736\n",
            "Epoch 104/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3276 - loss: 0.7075 - val_acc: 0.0617 - val_loss: 3.7474\n",
            "Epoch 105/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 362ms/step - acc: 0.2239 - loss: 0.6279 - val_acc: 0.2211 - val_loss: 1.8914\n",
            "Epoch 106/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2137 - loss: 0.8210 - val_acc: 0.0617 - val_loss: 3.8822\n",
            "Epoch 107/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.2217 - loss: 0.6558 - val_acc: 0.2238 - val_loss: 1.8487\n",
            "Epoch 108/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1966 - loss: 0.6062 - val_acc: 0.0864 - val_loss: 3.5785\n",
            "Epoch 109/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - acc: 0.2208 - loss: 0.6002 - val_acc: 0.2245 - val_loss: 1.8431\n",
            "Epoch 110/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2336 - loss: 0.7371 - val_acc: 0.0864 - val_loss: 3.5471\n",
            "Epoch 111/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - acc: 0.2075 - loss: 0.5942 - val_acc: 0.2251 - val_loss: 1.8263\n",
            "Epoch 112/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - acc: 0.2422 - loss: 0.6724 - val_acc: 0.0679 - val_loss: 3.5840\n",
            "Epoch 113/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - acc: 0.2058 - loss: 0.5812 - val_acc: 0.2259 - val_loss: 1.8088\n",
            "Epoch 114/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2664 - loss: 0.6730 - val_acc: 0.0802 - val_loss: 3.6486\n",
            "Epoch 115/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - acc: 0.2253 - loss: 0.5745 - val_acc: 0.2276 - val_loss: 1.8068\n",
            "Epoch 116/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.1781 - loss: 0.5886 - val_acc: 0.0741 - val_loss: 3.5598\n",
            "Epoch 117/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 335ms/step - acc: 0.2192 - loss: 0.5484 - val_acc: 0.2286 - val_loss: 1.8008\n",
            "Epoch 118/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3091 - loss: 0.5252 - val_acc: 0.0802 - val_loss: 3.5428\n",
            "Epoch 119/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2246 - loss: 0.5191 - val_acc: 0.2280 - val_loss: 1.7903\n",
            "Epoch 120/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2094 - loss: 0.5911 - val_acc: 0.0617 - val_loss: 3.6249\n",
            "Epoch 121/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - acc: 0.2321 - loss: 0.4916 - val_acc: 0.2305 - val_loss: 1.7640\n",
            "Epoch 122/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1909 - loss: 0.5933 - val_acc: 0.0617 - val_loss: 3.6738\n",
            "Epoch 123/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 320ms/step - acc: 0.2312 - loss: 0.4779 - val_acc: 0.2276 - val_loss: 1.7721\n",
            "Epoch 124/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2479 - loss: 0.4994 - val_acc: 0.0988 - val_loss: 3.4932\n",
            "Epoch 125/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - acc: 0.2244 - loss: 0.4531 - val_acc: 0.2290 - val_loss: 1.7847\n",
            "Epoch 126/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2493 - loss: 0.4391 - val_acc: 0.0864 - val_loss: 3.6546\n",
            "Epoch 127/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 294ms/step - acc: 0.2368 - loss: 0.4372 - val_acc: 0.2305 - val_loss: 1.7514\n",
            "Epoch 128/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.2308 - loss: 0.3382 - val_acc: 0.0864 - val_loss: 3.6042\n",
            "Epoch 129/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 436ms/step - acc: 0.2372 - loss: 0.4118 - val_acc: 0.2292 - val_loss: 1.7809\n",
            "Epoch 130/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - acc: 0.2322 - loss: 0.5523 - val_acc: 0.0926 - val_loss: 3.7093\n",
            "Epoch 131/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 253ms/step - acc: 0.2287 - loss: 0.3875 - val_acc: 0.2309 - val_loss: 1.7424\n",
            "Epoch 132/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2507 - loss: 0.2911 - val_acc: 0.0926 - val_loss: 3.6143\n",
            "Epoch 133/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 435ms/step - acc: 0.2326 - loss: 0.3779 - val_acc: 0.2328 - val_loss: 1.7332\n",
            "Epoch 134/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2479 - loss: 0.4675 - val_acc: 0.0926 - val_loss: 3.5602\n",
            "Epoch 135/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - acc: 0.2320 - loss: 0.3581 - val_acc: 0.2315 - val_loss: 1.7253\n",
            "Epoch 136/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2422 - loss: 0.3758 - val_acc: 0.0802 - val_loss: 3.5370\n",
            "Epoch 137/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 407ms/step - acc: 0.2331 - loss: 0.3599 - val_acc: 0.2348 - val_loss: 1.7152\n",
            "Epoch 138/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.3020 - loss: 0.2325 - val_acc: 0.0864 - val_loss: 3.5222\n",
            "Epoch 139/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - acc: 0.2545 - loss: 0.3285 - val_acc: 0.2319 - val_loss: 1.7558\n",
            "Epoch 140/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2778 - loss: 0.4108 - val_acc: 0.0864 - val_loss: 3.5772\n",
            "Epoch 141/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - acc: 0.2454 - loss: 0.3443 - val_acc: 0.2326 - val_loss: 1.7421\n",
            "Epoch 142/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2222 - loss: 0.5176 - val_acc: 0.0864 - val_loss: 3.4064\n",
            "Epoch 143/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - acc: 0.2315 - loss: 0.3217 - val_acc: 0.2336 - val_loss: 1.7210\n",
            "Epoch 144/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2678 - loss: 0.2807 - val_acc: 0.0926 - val_loss: 3.5976\n",
            "Epoch 145/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - acc: 0.2477 - loss: 0.3030 - val_acc: 0.2342 - val_loss: 1.7170\n",
            "Epoch 146/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2593 - loss: 0.2927 - val_acc: 0.0864 - val_loss: 3.4741\n",
            "Epoch 147/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - acc: 0.2434 - loss: 0.2875 - val_acc: 0.2346 - val_loss: 1.7258\n",
            "Epoch 148/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2578 - loss: 0.2387 - val_acc: 0.0926 - val_loss: 3.5802\n",
            "Epoch 149/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 342ms/step - acc: 0.2466 - loss: 0.2791 - val_acc: 0.2348 - val_loss: 1.6965\n",
            "Epoch 150/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - acc: 0.2607 - loss: 0.3287 - val_acc: 0.1049 - val_loss: 3.4500\n",
            "Epoch 151/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - acc: 0.2359 - loss: 0.2887 - val_acc: 0.2350 - val_loss: 1.7112\n",
            "Epoch 152/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2436 - loss: 0.2700 - val_acc: 0.0802 - val_loss: 3.5280\n",
            "Epoch 153/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - acc: 0.2372 - loss: 0.2741 - val_acc: 0.2344 - val_loss: 1.7215\n",
            "Epoch 154/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.2507 - loss: 0.2580 - val_acc: 0.0926 - val_loss: 3.4180\n",
            "Epoch 155/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 494ms/step - acc: 0.2501 - loss: 0.2544 - val_acc: 0.2361 - val_loss: 1.7019\n",
            "Epoch 156/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.1724 - loss: 0.2369 - val_acc: 0.0988 - val_loss: 3.3486\n",
            "Epoch 157/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 249ms/step - acc: 0.2393 - loss: 0.2368 - val_acc: 0.2351 - val_loss: 1.7016\n",
            "Epoch 158/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2208 - loss: 0.2919 - val_acc: 0.1049 - val_loss: 3.4499\n",
            "Epoch 159/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - acc: 0.2476 - loss: 0.2494 - val_acc: 0.2365 - val_loss: 1.6885\n",
            "Epoch 160/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2379 - loss: 0.1985 - val_acc: 0.1049 - val_loss: 3.5664\n",
            "Epoch 161/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - acc: 0.2422 - loss: 0.2341 - val_acc: 0.2369 - val_loss: 1.7103\n",
            "Epoch 162/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.3319 - loss: 0.3355 - val_acc: 0.0864 - val_loss: 3.4874\n",
            "Epoch 163/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - acc: 0.2448 - loss: 0.2271 - val_acc: 0.2357 - val_loss: 1.7317\n",
            "Epoch 164/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1425 - loss: 0.2385 - val_acc: 0.0926 - val_loss: 3.5545\n",
            "Epoch 165/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2346 - loss: 0.2287 - val_acc: 0.2363 - val_loss: 1.7018\n",
            "Epoch 166/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3960 - loss: 0.1871 - val_acc: 0.1111 - val_loss: 3.4502\n",
            "Epoch 167/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 320ms/step - acc: 0.2390 - loss: 0.2056 - val_acc: 0.2365 - val_loss: 1.7192\n",
            "Epoch 168/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - acc: 0.2877 - loss: 0.1911 - val_acc: 0.1173 - val_loss: 3.4372\n",
            "Epoch 169/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 327ms/step - acc: 0.2487 - loss: 0.2027 - val_acc: 0.2375 - val_loss: 1.7291\n",
            "Epoch 170/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.2422 - loss: 0.2372 - val_acc: 0.0988 - val_loss: 3.5349\n",
            "Epoch 171/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - acc: 0.2507 - loss: 0.2037 - val_acc: 0.2367 - val_loss: 1.7101\n",
            "Epoch 172/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2080 - loss: 0.2381 - val_acc: 0.1111 - val_loss: 3.3542\n",
            "Epoch 173/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.2358 - loss: 0.1911 - val_acc: 0.2363 - val_loss: 1.7411\n",
            "Epoch 174/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2393 - loss: 0.2763 - val_acc: 0.0988 - val_loss: 3.4671\n",
            "Epoch 175/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 364ms/step - acc: 0.2269 - loss: 0.1923 - val_acc: 0.2378 - val_loss: 1.7028\n",
            "Epoch 176/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2322 - loss: 0.2247 - val_acc: 0.1173 - val_loss: 3.4442\n",
            "Epoch 177/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 320ms/step - acc: 0.2418 - loss: 0.1838 - val_acc: 0.2382 - val_loss: 1.6959\n",
            "Epoch 178/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3162 - loss: 0.1979 - val_acc: 0.1049 - val_loss: 3.4095\n",
            "Epoch 179/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - acc: 0.2421 - loss: 0.1782 - val_acc: 0.2373 - val_loss: 1.7237\n",
            "Epoch 180/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.1823 - loss: 0.1629 - val_acc: 0.1049 - val_loss: 3.4912\n",
            "Epoch 181/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2611 - loss: 0.1814 - val_acc: 0.2382 - val_loss: 1.7145\n",
            "Epoch 182/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2821 - loss: 0.1676 - val_acc: 0.1111 - val_loss: 3.4582\n",
            "Epoch 183/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 371ms/step - acc: 0.2612 - loss: 0.1793 - val_acc: 0.2382 - val_loss: 1.7214\n",
            "Epoch 184/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.1638 - loss: 0.1080 - val_acc: 0.1111 - val_loss: 3.4774\n",
            "Epoch 185/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.2304 - loss: 0.1611 - val_acc: 0.2380 - val_loss: 1.7276\n",
            "Epoch 186/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2650 - loss: 0.2016 - val_acc: 0.1173 - val_loss: 3.4808\n",
            "Epoch 187/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - acc: 0.2458 - loss: 0.1698 - val_acc: 0.2378 - val_loss: 1.7328\n",
            "Epoch 188/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1795 - loss: 0.2010 - val_acc: 0.1111 - val_loss: 3.4942\n",
            "Epoch 189/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 404ms/step - acc: 0.2399 - loss: 0.1563 - val_acc: 0.2382 - val_loss: 1.7195\n",
            "Epoch 190/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2578 - loss: 0.2061 - val_acc: 0.1173 - val_loss: 3.5410\n",
            "Epoch 191/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - acc: 0.2507 - loss: 0.1631 - val_acc: 0.2371 - val_loss: 1.7213\n",
            "Epoch 192/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2450 - loss: 0.1133 - val_acc: 0.1111 - val_loss: 3.4159\n",
            "Epoch 193/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - acc: 0.2398 - loss: 0.1614 - val_acc: 0.2384 - val_loss: 1.7304\n",
            "Epoch 194/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2906 - loss: 0.1678 - val_acc: 0.1111 - val_loss: 3.4565\n",
            "Epoch 195/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 421ms/step - acc: 0.2464 - loss: 0.1514 - val_acc: 0.2369 - val_loss: 1.7510\n",
            "Epoch 196/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - acc: 0.2464 - loss: 0.1496 - val_acc: 0.1111 - val_loss: 3.5353\n",
            "Epoch 197/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - acc: 0.2454 - loss: 0.1449 - val_acc: 0.2375 - val_loss: 1.7272\n",
            "Epoch 198/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2265 - loss: 0.0911 - val_acc: 0.1111 - val_loss: 3.5762\n",
            "Epoch 199/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 426ms/step - acc: 0.2492 - loss: 0.1609 - val_acc: 0.2378 - val_loss: 1.7315\n",
            "Epoch 200/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2365 - loss: 0.1652 - val_acc: 0.1049 - val_loss: 3.5821\n",
            "Epoch 201/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 250ms/step - acc: 0.2412 - loss: 0.1475 - val_acc: 0.2394 - val_loss: 1.7328\n",
            "Epoch 202/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.2108 - loss: 0.1411 - val_acc: 0.1173 - val_loss: 3.4168\n",
            "Epoch 203/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 308ms/step - acc: 0.2650 - loss: 0.1391 - val_acc: 0.2384 - val_loss: 1.7539\n",
            "Epoch 204/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - acc: 0.2165 - loss: 0.1370 - val_acc: 0.1049 - val_loss: 3.5830\n",
            "Epoch 205/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 293ms/step - acc: 0.2366 - loss: 0.1282 - val_acc: 0.2371 - val_loss: 1.7529\n",
            "Epoch 206/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3319 - loss: 0.1589 - val_acc: 0.1111 - val_loss: 3.4707\n",
            "Epoch 207/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - acc: 0.2509 - loss: 0.1407 - val_acc: 0.2388 - val_loss: 1.7489\n",
            "Epoch 208/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2906 - loss: 0.0999 - val_acc: 0.1111 - val_loss: 3.5073\n",
            "Epoch 209/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - acc: 0.2392 - loss: 0.1227 - val_acc: 0.2390 - val_loss: 1.7489\n",
            "Epoch 210/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2877 - loss: 0.2268 - val_acc: 0.1111 - val_loss: 3.5147\n",
            "Epoch 211/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 336ms/step - acc: 0.2411 - loss: 0.1295 - val_acc: 0.2378 - val_loss: 1.7481\n",
            "Epoch 212/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2023 - loss: 0.1180 - val_acc: 0.1111 - val_loss: 3.5954\n",
            "Epoch 213/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - acc: 0.2390 - loss: 0.1253 - val_acc: 0.2386 - val_loss: 1.7582\n",
            "Epoch 214/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.3533 - loss: 0.1806 - val_acc: 0.1173 - val_loss: 3.4705\n",
            "Epoch 215/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - acc: 0.2600 - loss: 0.1191 - val_acc: 0.2378 - val_loss: 1.7874\n",
            "Epoch 216/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.1496 - loss: 0.1359 - val_acc: 0.1173 - val_loss: 3.4214\n",
            "Epoch 217/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - acc: 0.2421 - loss: 0.1372 - val_acc: 0.2394 - val_loss: 1.7538\n",
            "Epoch 218/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1695 - loss: 0.0799 - val_acc: 0.1173 - val_loss: 3.5770\n",
            "Epoch 219/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2480 - loss: 0.1201 - val_acc: 0.2388 - val_loss: 1.7640\n",
            "Epoch 220/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2365 - loss: 0.1123 - val_acc: 0.1173 - val_loss: 3.5341\n",
            "Epoch 221/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - acc: 0.2412 - loss: 0.1268 - val_acc: 0.2377 - val_loss: 1.7547\n",
            "Epoch 222/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2208 - loss: 0.0945 - val_acc: 0.1173 - val_loss: 3.6317\n",
            "Epoch 223/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - acc: 0.2358 - loss: 0.1156 - val_acc: 0.2396 - val_loss: 1.7595\n",
            "Epoch 224/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - acc: 0.3148 - loss: 0.1214 - val_acc: 0.1173 - val_loss: 3.5188\n",
            "Epoch 225/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - acc: 0.2635 - loss: 0.1159 - val_acc: 0.2378 - val_loss: 1.7681\n",
            "Epoch 226/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1382 - loss: 0.0881 - val_acc: 0.1173 - val_loss: 3.5960\n",
            "Epoch 227/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - acc: 0.2409 - loss: 0.1215 - val_acc: 0.2394 - val_loss: 1.7580\n",
            "Epoch 228/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.1681 - loss: 0.0684 - val_acc: 0.1111 - val_loss: 3.6503\n",
            "Epoch 229/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - acc: 0.2394 - loss: 0.1178 - val_acc: 0.2392 - val_loss: 1.7995\n",
            "Epoch 230/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2194 - loss: 0.0823 - val_acc: 0.1049 - val_loss: 3.5055\n",
            "Epoch 231/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 240ms/step - acc: 0.2437 - loss: 0.1181 - val_acc: 0.2394 - val_loss: 1.7692\n",
            "Epoch 232/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2692 - loss: 0.1480 - val_acc: 0.1173 - val_loss: 3.5099\n",
            "Epoch 233/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 438ms/step - acc: 0.2414 - loss: 0.1106 - val_acc: 0.2390 - val_loss: 1.7799\n",
            "Epoch 234/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.1866 - loss: 0.1190 - val_acc: 0.1111 - val_loss: 3.5228\n",
            "Epoch 235/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - acc: 0.2534 - loss: 0.1018 - val_acc: 0.2398 - val_loss: 1.7712\n",
            "Epoch 236/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.1724 - loss: 0.0926 - val_acc: 0.1111 - val_loss: 3.5857\n",
            "Epoch 237/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 286ms/step - acc: 0.2588 - loss: 0.1092 - val_acc: 0.2388 - val_loss: 1.7831\n",
            "Epoch 238/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2236 - loss: 0.2281 - val_acc: 0.1173 - val_loss: 3.5576\n",
            "Epoch 239/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 394ms/step - acc: 0.2491 - loss: 0.1132 - val_acc: 0.2394 - val_loss: 1.7802\n",
            "Epoch 240/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2222 - loss: 0.1502 - val_acc: 0.1173 - val_loss: 3.5924\n",
            "Epoch 241/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - acc: 0.2428 - loss: 0.1013 - val_acc: 0.2388 - val_loss: 1.7851\n",
            "Epoch 242/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2877 - loss: 0.1379 - val_acc: 0.1111 - val_loss: 3.5361\n",
            "Epoch 243/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - acc: 0.2433 - loss: 0.0969 - val_acc: 0.2388 - val_loss: 1.7770\n",
            "Epoch 244/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2151 - loss: 0.0494 - val_acc: 0.1111 - val_loss: 3.6555\n",
            "Epoch 245/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 361ms/step - acc: 0.2412 - loss: 0.1065 - val_acc: 0.2390 - val_loss: 1.7762\n",
            "Epoch 246/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2066 - loss: 0.1311 - val_acc: 0.1173 - val_loss: 3.6639\n",
            "Epoch 247/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - acc: 0.2366 - loss: 0.1019 - val_acc: 0.2396 - val_loss: 1.7874\n",
            "Epoch 248/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3462 - loss: 0.0650 - val_acc: 0.1111 - val_loss: 3.6307\n",
            "Epoch 249/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - acc: 0.2507 - loss: 0.0972 - val_acc: 0.2392 - val_loss: 1.7885\n",
            "Epoch 250/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2479 - loss: 0.1708 - val_acc: 0.1173 - val_loss: 3.5406\n",
            "Epoch 251/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - acc: 0.2475 - loss: 0.0981 - val_acc: 0.2388 - val_loss: 1.8240\n",
            "Epoch 252/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - acc: 0.2407 - loss: 0.1127 - val_acc: 0.1173 - val_loss: 3.5403\n",
            "Epoch 253/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - acc: 0.2499 - loss: 0.0992 - val_acc: 0.2398 - val_loss: 1.8033\n",
            "Epoch 254/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1524 - loss: 0.0582 - val_acc: 0.1111 - val_loss: 3.5118\n",
            "Epoch 255/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - acc: 0.2530 - loss: 0.1032 - val_acc: 0.2402 - val_loss: 1.8002\n",
            "Epoch 256/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2094 - loss: 0.0722 - val_acc: 0.1111 - val_loss: 3.5655\n",
            "Epoch 257/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 340ms/step - acc: 0.2337 - loss: 0.0955 - val_acc: 0.2386 - val_loss: 1.8126\n",
            "Epoch 258/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2322 - loss: 0.0288 - val_acc: 0.1111 - val_loss: 3.6391\n",
            "Epoch 259/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - acc: 0.2449 - loss: 0.1014 - val_acc: 0.2404 - val_loss: 1.7992\n",
            "Epoch 260/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2778 - loss: 0.1517 - val_acc: 0.1173 - val_loss: 3.6206\n",
            "Epoch 261/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - acc: 0.2362 - loss: 0.0920 - val_acc: 0.2398 - val_loss: 1.8047\n",
            "Epoch 262/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1937 - loss: 0.1116 - val_acc: 0.1173 - val_loss: 3.5899\n",
            "Epoch 263/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - acc: 0.2491 - loss: 0.1035 - val_acc: 0.2398 - val_loss: 1.8029\n",
            "Epoch 264/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.3048 - loss: 0.1330 - val_acc: 0.1173 - val_loss: 3.5744\n",
            "Epoch 265/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - acc: 0.2499 - loss: 0.1016 - val_acc: 0.2390 - val_loss: 1.8009\n",
            "Epoch 266/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2222 - loss: 0.1788 - val_acc: 0.1173 - val_loss: 3.7588\n",
            "Epoch 267/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 244ms/step - acc: 0.2509 - loss: 0.0945 - val_acc: 0.2386 - val_loss: 1.8068\n",
            "Epoch 268/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2521 - loss: 0.1291 - val_acc: 0.1111 - val_loss: 3.7441\n",
            "Epoch 269/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 340ms/step - acc: 0.2475 - loss: 0.0911 - val_acc: 0.2384 - val_loss: 1.8101\n",
            "Epoch 270/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - acc: 0.2251 - loss: 0.1460 - val_acc: 0.1049 - val_loss: 3.6617\n",
            "Epoch 271/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step - acc: 0.2392 - loss: 0.0775 - val_acc: 0.2400 - val_loss: 1.8140\n",
            "Epoch 272/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2450 - loss: 0.0659 - val_acc: 0.1111 - val_loss: 3.6672\n",
            "Epoch 273/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 246ms/step - acc: 0.2463 - loss: 0.0820 - val_acc: 0.2398 - val_loss: 1.8050\n",
            "Epoch 274/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1852 - loss: 0.0806 - val_acc: 0.1173 - val_loss: 3.7349\n",
            "Epoch 275/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 356ms/step - acc: 0.2459 - loss: 0.0860 - val_acc: 0.2390 - val_loss: 1.8283\n",
            "Epoch 276/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2892 - loss: 0.1662 - val_acc: 0.1173 - val_loss: 3.6813\n",
            "Epoch 277/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - acc: 0.2509 - loss: 0.0811 - val_acc: 0.2394 - val_loss: 1.8131\n",
            "Epoch 278/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.3091 - loss: 0.1388 - val_acc: 0.1111 - val_loss: 3.7245\n",
            "Epoch 279/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2418 - loss: 0.0940 - val_acc: 0.2388 - val_loss: 1.8322\n",
            "Epoch 280/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2009 - loss: 0.0779 - val_acc: 0.1173 - val_loss: 3.8781\n",
            "Epoch 281/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - acc: 0.2497 - loss: 0.0841 - val_acc: 0.2405 - val_loss: 1.8054\n",
            "Epoch 282/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2407 - loss: 0.0874 - val_acc: 0.1173 - val_loss: 3.7490\n",
            "Epoch 283/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - acc: 0.2587 - loss: 0.0958 - val_acc: 0.2396 - val_loss: 1.8330\n",
            "Epoch 284/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2236 - loss: 0.0320 - val_acc: 0.1111 - val_loss: 3.6461\n",
            "Epoch 285/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - acc: 0.2467 - loss: 0.0798 - val_acc: 0.2402 - val_loss: 1.8349\n",
            "Epoch 286/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2536 - loss: 0.0823 - val_acc: 0.0988 - val_loss: 4.1456\n",
            "Epoch 287/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - acc: 0.2370 - loss: 0.0892 - val_acc: 0.2400 - val_loss: 1.8282\n",
            "Epoch 288/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.1567 - loss: 0.0361 - val_acc: 0.1173 - val_loss: 3.8543\n",
            "Epoch 289/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - acc: 0.2486 - loss: 0.0965 - val_acc: 0.2398 - val_loss: 1.8272\n",
            "Epoch 290/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2137 - loss: 0.1438 - val_acc: 0.1173 - val_loss: 3.7833\n",
            "Epoch 291/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - acc: 0.2491 - loss: 0.0798 - val_acc: 0.2394 - val_loss: 1.8360\n",
            "Epoch 292/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.3704 - loss: 0.1283 - val_acc: 0.1173 - val_loss: 3.8198\n",
            "Epoch 293/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 236ms/step - acc: 0.2599 - loss: 0.0859 - val_acc: 0.2404 - val_loss: 1.8404\n",
            "Epoch 294/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.3276 - loss: 0.0380 - val_acc: 0.1173 - val_loss: 3.7630\n",
            "Epoch 295/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - acc: 0.2575 - loss: 0.0949 - val_acc: 0.2402 - val_loss: 1.8287\n",
            "Epoch 296/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - acc: 0.1795 - loss: 0.0423 - val_acc: 0.1111 - val_loss: 3.7241\n",
            "Epoch 297/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - acc: 0.2468 - loss: 0.0832 - val_acc: 0.2398 - val_loss: 1.8395\n",
            "Epoch 298/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2564 - loss: 0.1296 - val_acc: 0.1173 - val_loss: 3.7586\n",
            "Epoch 299/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - acc: 0.2374 - loss: 0.0795 - val_acc: 0.2415 - val_loss: 1.8391\n",
            "Epoch 300/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2877 - loss: 0.1290 - val_acc: 0.1173 - val_loss: 3.8326\n",
            "Epoch 301/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - acc: 0.2421 - loss: 0.0762 - val_acc: 0.2411 - val_loss: 1.8333\n",
            "Epoch 302/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.2009 - loss: 0.1023 - val_acc: 0.1111 - val_loss: 3.8073\n",
            "Epoch 303/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - acc: 0.2495 - loss: 0.0893 - val_acc: 0.2415 - val_loss: 1.8474\n",
            "Epoch 304/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2179 - loss: 0.0288 - val_acc: 0.1173 - val_loss: 3.7269\n",
            "Epoch 305/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - acc: 0.2606 - loss: 0.0822 - val_acc: 0.2405 - val_loss: 1.8355\n",
            "Epoch 306/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.2094 - loss: 0.0442 - val_acc: 0.1173 - val_loss: 3.7277\n",
            "Epoch 307/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - acc: 0.2582 - loss: 0.0780 - val_acc: 0.2402 - val_loss: 1.8470\n",
            "Epoch 308/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2037 - loss: 0.1393 - val_acc: 0.1173 - val_loss: 3.8772\n",
            "Epoch 309/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 248ms/step - acc: 0.2346 - loss: 0.0759 - val_acc: 0.2400 - val_loss: 1.8310\n",
            "Epoch 310/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.3462 - loss: 0.0408 - val_acc: 0.1173 - val_loss: 3.7175\n",
            "Epoch 311/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - acc: 0.2608 - loss: 0.0844 - val_acc: 0.2419 - val_loss: 1.8426\n",
            "Epoch 312/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2664 - loss: 0.0804 - val_acc: 0.1173 - val_loss: 3.6823\n",
            "Epoch 313/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - acc: 0.2435 - loss: 0.0776 - val_acc: 0.2411 - val_loss: 1.8401\n",
            "Epoch 314/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1980 - loss: 0.0502 - val_acc: 0.1173 - val_loss: 3.9013\n",
            "Epoch 315/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - acc: 0.2399 - loss: 0.0762 - val_acc: 0.2396 - val_loss: 1.8687\n",
            "Epoch 316/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.3191 - loss: 0.0672 - val_acc: 0.1173 - val_loss: 3.7911\n",
            "Epoch 317/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - acc: 0.2546 - loss: 0.0735 - val_acc: 0.2421 - val_loss: 1.8404\n",
            "Epoch 318/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2080 - loss: 0.0845 - val_acc: 0.1111 - val_loss: 3.7861\n",
            "Epoch 319/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - acc: 0.2482 - loss: 0.0857 - val_acc: 0.2419 - val_loss: 1.8502\n",
            "Epoch 320/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2721 - loss: 0.1458 - val_acc: 0.1173 - val_loss: 3.7087\n",
            "Epoch 321/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 417ms/step - acc: 0.2551 - loss: 0.0763 - val_acc: 0.2400 - val_loss: 1.8565\n",
            "Epoch 322/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2464 - loss: 0.0374 - val_acc: 0.1235 - val_loss: 3.6843\n",
            "Epoch 323/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - acc: 0.2491 - loss: 0.0758 - val_acc: 0.2407 - val_loss: 1.8462\n",
            "Epoch 324/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.3903 - loss: 0.2028 - val_acc: 0.1173 - val_loss: 3.8230\n",
            "Epoch 325/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - acc: 0.2509 - loss: 0.0741 - val_acc: 0.2413 - val_loss: 1.8720\n",
            "Epoch 326/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2422 - loss: 0.1603 - val_acc: 0.1173 - val_loss: 3.7714\n",
            "Epoch 327/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - acc: 0.2473 - loss: 0.0988 - val_acc: 0.2417 - val_loss: 1.8618\n",
            "Epoch 328/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - acc: 0.1738 - loss: 0.0175 - val_acc: 0.1173 - val_loss: 3.8486\n",
            "Epoch 329/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 246ms/step - acc: 0.2413 - loss: 0.0681 - val_acc: 0.2404 - val_loss: 1.8666\n",
            "Epoch 330/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.2621 - loss: 0.1533 - val_acc: 0.1173 - val_loss: 3.8198\n",
            "Epoch 331/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 436ms/step - acc: 0.2407 - loss: 0.0687 - val_acc: 0.2415 - val_loss: 1.8669\n",
            "Epoch 332/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - acc: 0.1852 - loss: 0.0160 - val_acc: 0.1173 - val_loss: 3.8368\n",
            "Epoch 333/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - acc: 0.2502 - loss: 0.0658 - val_acc: 0.2415 - val_loss: 1.8581\n",
            "Epoch 334/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.3419 - loss: 0.0934 - val_acc: 0.1173 - val_loss: 3.8511\n",
            "Epoch 335/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - acc: 0.2418 - loss: 0.0723 - val_acc: 0.2388 - val_loss: 1.8795\n",
            "Epoch 336/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.2764 - loss: 0.1359 - val_acc: 0.1111 - val_loss: 3.8106\n",
            "Epoch 337/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 431ms/step - acc: 0.2449 - loss: 0.0795 - val_acc: 0.2423 - val_loss: 1.8637\n",
            "Epoch 338/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2023 - loss: 0.0447 - val_acc: 0.1173 - val_loss: 3.8062\n",
            "Epoch 339/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - acc: 0.2453 - loss: 0.0643 - val_acc: 0.2407 - val_loss: 1.8701\n",
            "Epoch 340/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - acc: 0.1567 - loss: 0.0414 - val_acc: 0.1173 - val_loss: 3.8705\n",
            "Epoch 341/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 460ms/step - acc: 0.2567 - loss: 0.0718 - val_acc: 0.2407 - val_loss: 1.8644\n",
            "Epoch 342/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.2137 - loss: 0.0879 - val_acc: 0.1173 - val_loss: 3.9176\n",
            "Epoch 343/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 523ms/step - acc: 0.2459 - loss: 0.0731 - val_acc: 0.2407 - val_loss: 1.8637\n",
            "Epoch 344/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.2350 - loss: 0.1114 - val_acc: 0.1173 - val_loss: 3.8015\n",
            "Epoch 345/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 515ms/step - acc: 0.2517 - loss: 0.0672 - val_acc: 0.2415 - val_loss: 1.8604\n",
            "Epoch 346/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.2137 - loss: 0.0318 - val_acc: 0.1173 - val_loss: 3.8447\n",
            "Epoch 347/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 653ms/step - acc: 0.2458 - loss: 0.0725 - val_acc: 0.2421 - val_loss: 1.8861\n",
            "Epoch 348/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.2436 - loss: 0.0655 - val_acc: 0.1173 - val_loss: 3.7701\n",
            "Epoch 349/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - acc: 0.2397 - loss: 0.0696 - val_acc: 0.2419 - val_loss: 1.8711\n",
            "Epoch 350/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2051 - loss: 0.0429 - val_acc: 0.1173 - val_loss: 3.7733\n",
            "Epoch 351/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 405ms/step - acc: 0.2491 - loss: 0.0721 - val_acc: 0.2421 - val_loss: 1.8790\n",
            "Epoch 352/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2521 - loss: 0.0389 - val_acc: 0.1173 - val_loss: 3.8063\n",
            "Epoch 353/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 340ms/step - acc: 0.2463 - loss: 0.0688 - val_acc: 0.2409 - val_loss: 1.8810\n",
            "Epoch 354/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2849 - loss: 0.1247 - val_acc: 0.1173 - val_loss: 3.7916\n",
            "Epoch 355/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - acc: 0.2626 - loss: 0.0801 - val_acc: 0.2419 - val_loss: 1.8766\n",
            "Epoch 356/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1980 - loss: 0.0292 - val_acc: 0.1173 - val_loss: 4.0075\n",
            "Epoch 357/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 431ms/step - acc: 0.2512 - loss: 0.0821 - val_acc: 0.2413 - val_loss: 1.8694\n",
            "Epoch 358/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - acc: 0.2749 - loss: 0.0345 - val_acc: 0.1173 - val_loss: 3.8401\n",
            "Epoch 359/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - acc: 0.2370 - loss: 0.0606 - val_acc: 0.2423 - val_loss: 1.8852\n",
            "Epoch 360/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2664 - loss: 0.0733 - val_acc: 0.1235 - val_loss: 3.7995\n",
            "Epoch 361/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - acc: 0.2387 - loss: 0.0614 - val_acc: 0.2413 - val_loss: 1.8934\n",
            "Epoch 362/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.1766 - loss: 0.0319 - val_acc: 0.1173 - val_loss: 3.8233\n",
            "Epoch 363/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343ms/step - acc: 0.2638 - loss: 0.0712 - val_acc: 0.2423 - val_loss: 1.8956\n",
            "Epoch 364/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.2550 - loss: 0.0357 - val_acc: 0.1173 - val_loss: 3.7477\n",
            "Epoch 365/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - acc: 0.2435 - loss: 0.0551 - val_acc: 0.2425 - val_loss: 1.8865\n",
            "Epoch 366/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1952 - loss: 0.1355 - val_acc: 0.1173 - val_loss: 3.8668\n",
            "Epoch 367/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - acc: 0.2493 - loss: 0.0603 - val_acc: 0.2427 - val_loss: 1.8926\n",
            "Epoch 368/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.2464 - loss: 0.0187 - val_acc: 0.1173 - val_loss: 3.7708\n",
            "Epoch 369/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 322ms/step - acc: 0.2484 - loss: 0.0627 - val_acc: 0.2425 - val_loss: 1.8834\n",
            "Epoch 370/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.2194 - loss: 0.0745 - val_acc: 0.1173 - val_loss: 4.0265\n",
            "Epoch 371/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 474ms/step - acc: 0.2395 - loss: 0.0690 - val_acc: 0.2419 - val_loss: 1.8842\n",
            "Epoch 372/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.3091 - loss: 0.1006 - val_acc: 0.1173 - val_loss: 3.8612\n",
            "Epoch 373/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 248ms/step - acc: 0.2556 - loss: 0.0578 - val_acc: 0.2411 - val_loss: 1.8802\n",
            "Epoch 374/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.2949 - loss: 0.1709 - val_acc: 0.1173 - val_loss: 3.8886\n",
            "Epoch 375/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - acc: 0.2511 - loss: 0.0712 - val_acc: 0.2413 - val_loss: 1.8984\n",
            "Epoch 376/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.2094 - loss: 0.0203 - val_acc: 0.1173 - val_loss: 3.8756\n",
            "Epoch 377/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 378ms/step - acc: 0.2545 - loss: 0.0618 - val_acc: 0.2421 - val_loss: 1.8795\n",
            "Epoch 378/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.1994 - loss: 0.0833 - val_acc: 0.1111 - val_loss: 3.7794\n",
            "Epoch 379/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - acc: 0.2532 - loss: 0.0661 - val_acc: 0.2425 - val_loss: 1.8827\n",
            "Epoch 380/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.2350 - loss: 0.0543 - val_acc: 0.1173 - val_loss: 3.8946\n",
            "Epoch 381/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - acc: 0.2464 - loss: 0.0621 - val_acc: 0.2431 - val_loss: 1.8839\n",
            "Epoch 382/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - acc: 0.2350 - loss: 0.1242 - val_acc: 0.1173 - val_loss: 3.8455\n",
            "Epoch 383/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - acc: 0.2440 - loss: 0.0700 - val_acc: 0.2427 - val_loss: 1.8771\n",
            "Epoch 384/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.2721 - loss: 0.0294 - val_acc: 0.1111 - val_loss: 3.9360\n",
            "Epoch 385/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 254ms/step - acc: 0.2456 - loss: 0.0583 - val_acc: 0.2413 - val_loss: 1.9228\n",
            "Epoch 386/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.3376 - loss: 0.1196 - val_acc: 0.1173 - val_loss: 3.9138\n",
            "Epoch 387/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - acc: 0.2417 - loss: 0.0540 - val_acc: 0.2427 - val_loss: 1.8835\n",
            "Epoch 388/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2393 - loss: 0.0593 - val_acc: 0.1173 - val_loss: 3.7969\n",
            "Epoch 389/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 742ms/step - acc: 0.2441 - loss: 0.0598 - val_acc: 0.2429 - val_loss: 1.8882\n",
            "Epoch 390/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.2977 - loss: 0.0307 - val_acc: 0.1173 - val_loss: 3.8870\n",
            "Epoch 391/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - acc: 0.2542 - loss: 0.0640 - val_acc: 0.2427 - val_loss: 1.9069\n",
            "Epoch 392/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2635 - loss: 0.1071 - val_acc: 0.1111 - val_loss: 3.9824\n",
            "Epoch 393/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - acc: 0.2590 - loss: 0.0606 - val_acc: 0.2427 - val_loss: 1.9348\n",
            "Epoch 394/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 0.1937 - loss: 0.0381 - val_acc: 0.1173 - val_loss: 4.0271\n",
            "Epoch 395/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 416ms/step - acc: 0.2681 - loss: 0.0738 - val_acc: 0.2432 - val_loss: 1.9076\n",
            "Epoch 396/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - acc: 0.2123 - loss: 0.0411 - val_acc: 0.1173 - val_loss: 3.8953\n",
            "Epoch 397/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - acc: 0.2611 - loss: 0.0591 - val_acc: 0.2427 - val_loss: 1.9015\n",
            "Epoch 398/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.1795 - loss: 0.0333 - val_acc: 0.1173 - val_loss: 3.7413\n",
            "Epoch 399/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - acc: 0.2560 - loss: 0.0624 - val_acc: 0.2425 - val_loss: 1.9008\n",
            "Epoch 400/400\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - acc: 0.2934 - loss: 0.0472 - val_acc: 0.1173 - val_loss: 3.9088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "JFlIXjA-YeIx",
        "outputId": "9a77a894-224f-4385-e5be-db31eb8b36cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 128)            96000     ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 128)            92416     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 128),                131584    ['embedding[0][0]']           \n",
            "                              (None, 128),                                                        \n",
            "                              (None, 128)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 128),          131584    ['embedding_1[0][0]',         \n",
            "                              (None, 128),                           'lstm[0][1]',                \n",
            "                              (None, 128)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 722)            93138     ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 544722 (2.08 MB)\n",
            "Trainable params: 544722 (2.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-082615c0824e>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history=model.fit_generator(generate_batch(trainX, trainY, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 18s 739ms/step - loss: 6.5627 - acc: 0.0882 - val_loss: 6.5215 - val_acc: 0.0704\n",
            "Epoch 2/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 6.1338 - acc: 0.0794 - val_loss: 5.6482 - val_acc: 0.0520\n",
            "Epoch 3/400\n",
            "12/12 [==============================] - 3s 263ms/step - loss: 5.4025 - acc: 0.0759 - val_loss: 5.2137 - val_acc: 0.0551\n",
            "Epoch 4/400\n",
            "12/12 [==============================] - 6s 489ms/step - loss: 5.1961 - acc: 0.0801 - val_loss: 5.1336 - val_acc: 0.1095\n",
            "Epoch 5/400\n",
            "12/12 [==============================] - 4s 288ms/step - loss: 5.1342 - acc: 0.0777 - val_loss: 5.3333 - val_acc: 0.0567\n",
            "Epoch 6/400\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 5.1069 - acc: 0.0839 - val_loss: 5.1035 - val_acc: 0.0608\n",
            "Epoch 7/400\n",
            "12/12 [==============================] - 3s 272ms/step - loss: 5.0171 - acc: 0.0844 - val_loss: 5.0035 - val_acc: 0.1323\n",
            "Epoch 8/400\n",
            "12/12 [==============================] - 5s 432ms/step - loss: 4.9522 - acc: 0.0909 - val_loss: 5.2208 - val_acc: 0.0753\n",
            "Epoch 9/400\n",
            "12/12 [==============================] - 4s 333ms/step - loss: 4.9012 - acc: 0.1023 - val_loss: 4.9552 - val_acc: 0.0641\n",
            "Epoch 10/400\n",
            "12/12 [==============================] - 3s 273ms/step - loss: 4.8223 - acc: 0.1222 - val_loss: 4.9111 - val_acc: 0.1465\n",
            "Epoch 11/400\n",
            "12/12 [==============================] - 3s 275ms/step - loss: 4.8444 - acc: 0.1129 - val_loss: 4.9359 - val_acc: 0.1044\n",
            "Epoch 12/400\n",
            "12/12 [==============================] - 5s 418ms/step - loss: 4.8270 - acc: 0.1353 - val_loss: 5.0909 - val_acc: 0.1157\n",
            "Epoch 13/400\n",
            "12/12 [==============================] - 4s 355ms/step - loss: 4.8248 - acc: 0.1433 - val_loss: 4.8315 - val_acc: 0.1126\n",
            "Epoch 14/400\n",
            "12/12 [==============================] - 3s 262ms/step - loss: 4.7118 - acc: 0.1544 - val_loss: 4.7664 - val_acc: 0.2148\n",
            "Epoch 15/400\n",
            "12/12 [==============================] - 3s 267ms/step - loss: 4.6037 - acc: 0.1631 - val_loss: 4.7859 - val_acc: 0.1677\n",
            "Epoch 16/400\n",
            "12/12 [==============================] - 4s 335ms/step - loss: 4.5800 - acc: 0.1637 - val_loss: 4.9365 - val_acc: 0.1467\n",
            "Epoch 17/400\n",
            "12/12 [==============================] - 5s 427ms/step - loss: 4.5536 - acc: 0.1709 - val_loss: 4.7388 - val_acc: 0.1191\n",
            "Epoch 18/400\n",
            "12/12 [==============================] - 3s 254ms/step - loss: 4.5404 - acc: 0.1640 - val_loss: 4.6422 - val_acc: 0.2119\n",
            "Epoch 19/400\n",
            "12/12 [==============================] - 3s 260ms/step - loss: 4.5457 - acc: 0.1640 - val_loss: 4.6900 - val_acc: 0.1530\n",
            "Epoch 20/400\n",
            "12/12 [==============================] - 3s 257ms/step - loss: 4.4687 - acc: 0.1661 - val_loss: 4.8480 - val_acc: 0.1561\n",
            "Epoch 21/400\n",
            "12/12 [==============================] - 6s 472ms/step - loss: 4.4312 - acc: 0.1669 - val_loss: 4.6229 - val_acc: 0.1643\n",
            "Epoch 22/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 4.4009 - acc: 0.1706 - val_loss: 4.5744 - val_acc: 0.2162\n",
            "Epoch 23/400\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 4.3258 - acc: 0.1916 - val_loss: 4.5988 - val_acc: 0.1748\n",
            "Epoch 24/400\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 4.3866 - acc: 0.1678 - val_loss: 4.7619 - val_acc: 0.1693\n",
            "Epoch 25/400\n",
            "12/12 [==============================] - 6s 471ms/step - loss: 4.3889 - acc: 0.1678 - val_loss: 4.5494 - val_acc: 0.1791\n",
            "Epoch 26/400\n",
            "12/12 [==============================] - 3s 266ms/step - loss: 4.4306 - acc: 0.1685 - val_loss: 4.4751 - val_acc: 0.2148\n",
            "Epoch 27/400\n",
            "12/12 [==============================] - 3s 274ms/step - loss: 4.2923 - acc: 0.1757 - val_loss: 4.6949 - val_acc: 0.1724\n",
            "Epoch 28/400\n",
            "12/12 [==============================] - 5s 457ms/step - loss: 4.1800 - acc: 0.1852 - val_loss: 4.4436 - val_acc: 0.1758\n",
            "Epoch 29/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 4.1834 - acc: 0.1835 - val_loss: 4.4529 - val_acc: 0.2205\n",
            "Epoch 30/400\n",
            "12/12 [==============================] - 3s 266ms/step - loss: 4.1794 - acc: 0.1858 - val_loss: 4.4779 - val_acc: 0.1652\n",
            "Epoch 31/400\n",
            "12/12 [==============================] - 3s 255ms/step - loss: 4.1791 - acc: 0.1784 - val_loss: 4.6830 - val_acc: 0.1568\n",
            "Epoch 32/400\n",
            "12/12 [==============================] - 6s 544ms/step - loss: 4.2083 - acc: 0.1749 - val_loss: 4.4126 - val_acc: 0.1627\n",
            "Epoch 33/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 4.1343 - acc: 0.1801 - val_loss: 4.3937 - val_acc: 0.2361\n",
            "Epoch 34/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 4.1103 - acc: 0.1834 - val_loss: 4.6223 - val_acc: 0.1700\n",
            "Epoch 35/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 4.0836 - acc: 0.1903 - val_loss: 4.3338 - val_acc: 0.1783\n",
            "Epoch 36/400\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 4.0109 - acc: 0.2143 - val_loss: 4.3559 - val_acc: 0.2432\n",
            "Epoch 37/400\n",
            "12/12 [==============================] - 4s 292ms/step - loss: 4.0838 - acc: 0.1870 - val_loss: 4.3548 - val_acc: 0.1946\n",
            "Epoch 38/400\n",
            "12/12 [==============================] - 3s 268ms/step - loss: 4.1013 - acc: 0.1809 - val_loss: 4.5397 - val_acc: 0.1801\n",
            "Epoch 39/400\n",
            "12/12 [==============================] - 3s 270ms/step - loss: 4.1360 - acc: 0.1876 - val_loss: 4.2366 - val_acc: 0.1997\n",
            "Epoch 40/400\n",
            "12/12 [==============================] - 5s 476ms/step - loss: 3.9887 - acc: 0.1977 - val_loss: 4.2775 - val_acc: 0.2489\n",
            "Epoch 41/400\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 3.8590 - acc: 0.2144 - val_loss: 4.4855 - val_acc: 0.2019\n",
            "Epoch 42/400\n",
            "12/12 [==============================] - 3s 260ms/step - loss: 3.8634 - acc: 0.2124 - val_loss: 4.1817 - val_acc: 0.2325\n",
            "Epoch 43/400\n",
            "12/12 [==============================] - 3s 251ms/step - loss: 3.8677 - acc: 0.2170 - val_loss: 4.2568 - val_acc: 0.2546\n",
            "Epoch 44/400\n",
            "12/12 [==============================] - 5s 449ms/step - loss: 3.8580 - acc: 0.2119 - val_loss: 4.2239 - val_acc: 0.2049\n",
            "Epoch 45/400\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 3.9095 - acc: 0.2062 - val_loss: 4.4307 - val_acc: 0.1825\n",
            "Epoch 46/400\n",
            "12/12 [==============================] - 3s 268ms/step - loss: 3.8060 - acc: 0.2150 - val_loss: 4.0921 - val_acc: 0.2054\n",
            "Epoch 47/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 3.7791 - acc: 0.2202 - val_loss: 4.1932 - val_acc: 0.2632\n",
            "Epoch 48/400\n",
            "12/12 [==============================] - 4s 360ms/step - loss: 3.7519 - acc: 0.2253 - val_loss: 4.1441 - val_acc: 0.2260\n",
            "Epoch 49/400\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 3.6810 - acc: 0.2542 - val_loss: 4.3523 - val_acc: 0.2034\n",
            "Epoch 50/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 3.7503 - acc: 0.2273 - val_loss: 4.0125 - val_acc: 0.2161\n",
            "Epoch 51/400\n",
            "12/12 [==============================] - 3s 260ms/step - loss: 3.7802 - acc: 0.2237 - val_loss: 4.1010 - val_acc: 0.2703\n",
            "Epoch 52/400\n",
            "12/12 [==============================] - 4s 296ms/step - loss: 3.7884 - acc: 0.2332 - val_loss: 4.0182 - val_acc: 0.2452\n",
            "Epoch 53/400\n",
            "12/12 [==============================] - 6s 464ms/step - loss: 3.6379 - acc: 0.2425 - val_loss: 4.2420 - val_acc: 0.2337\n",
            "Epoch 54/400\n",
            "12/12 [==============================] - 3s 273ms/step - loss: 3.5016 - acc: 0.2654 - val_loss: 3.8547 - val_acc: 0.2720\n",
            "Epoch 55/400\n",
            "12/12 [==============================] - 3s 249ms/step - loss: 3.5053 - acc: 0.2524 - val_loss: 4.0459 - val_acc: 0.2745\n",
            "Epoch 56/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 3.5045 - acc: 0.2548 - val_loss: 3.9686 - val_acc: 0.2586\n",
            "Epoch 57/400\n",
            "12/12 [==============================] - 5s 476ms/step - loss: 3.4969 - acc: 0.2582 - val_loss: 4.1774 - val_acc: 0.2562\n",
            "Epoch 58/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 3.5469 - acc: 0.2475 - val_loss: 3.7778 - val_acc: 0.2703\n",
            "Epoch 59/400\n",
            "12/12 [==============================] - 3s 254ms/step - loss: 3.4380 - acc: 0.2602 - val_loss: 3.9640 - val_acc: 0.2987\n",
            "Epoch 60/400\n",
            "12/12 [==============================] - 4s 354ms/step - loss: 3.4127 - acc: 0.2649 - val_loss: 3.8642 - val_acc: 0.2855\n",
            "Epoch 61/400\n",
            "12/12 [==============================] - 9s 745ms/step - loss: 3.3950 - acc: 0.2723 - val_loss: 4.0742 - val_acc: 0.2787\n",
            "Epoch 62/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 3.3071 - acc: 0.2984 - val_loss: 3.6518 - val_acc: 0.3098\n",
            "Epoch 63/400\n",
            "12/12 [==============================] - 3s 247ms/step - loss: 3.3953 - acc: 0.2706 - val_loss: 3.8922 - val_acc: 0.3001\n",
            "Epoch 64/400\n",
            "12/12 [==============================] - 4s 386ms/step - loss: 3.4030 - acc: 0.2678 - val_loss: 3.7439 - val_acc: 0.3060\n",
            "Epoch 65/400\n",
            "12/12 [==============================] - 4s 357ms/step - loss: 3.4081 - acc: 0.2787 - val_loss: 3.9791 - val_acc: 0.3082\n",
            "Epoch 66/400\n",
            "12/12 [==============================] - 3s 262ms/step - loss: 3.2639 - acc: 0.2867 - val_loss: 3.5379 - val_acc: 0.3246\n",
            "Epoch 67/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 3.1125 - acc: 0.3120 - val_loss: 3.8137 - val_acc: 0.3044\n",
            "Epoch 68/400\n",
            "12/12 [==============================] - 4s 318ms/step - loss: 3.1355 - acc: 0.3065 - val_loss: 3.6646 - val_acc: 0.3195\n",
            "Epoch 69/400\n",
            "12/12 [==============================] - 6s 458ms/step - loss: 3.1435 - acc: 0.2980 - val_loss: 3.9084 - val_acc: 0.3043\n",
            "Epoch 70/400\n",
            "12/12 [==============================] - 3s 252ms/step - loss: 3.1230 - acc: 0.3076 - val_loss: 3.4966 - val_acc: 0.3172\n",
            "Epoch 71/400\n",
            "12/12 [==============================] - 3s 252ms/step - loss: 3.1725 - acc: 0.2966 - val_loss: 3.7514 - val_acc: 0.3044\n",
            "Epoch 72/400\n",
            "12/12 [==============================] - 3s 266ms/step - loss: 3.0710 - acc: 0.3083 - val_loss: 3.6005 - val_acc: 0.3105\n",
            "Epoch 73/400\n",
            "12/12 [==============================] - 6s 490ms/step - loss: 3.0428 - acc: 0.3232 - val_loss: 3.8462 - val_acc: 0.3168\n",
            "Epoch 74/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 3.0125 - acc: 0.3284 - val_loss: 3.4011 - val_acc: 0.3418\n",
            "Epoch 75/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 2.9517 - acc: 0.3593 - val_loss: 3.6994 - val_acc: 0.3115\n",
            "Epoch 76/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 3.0218 - acc: 0.3219 - val_loss: 3.4781 - val_acc: 0.3739\n",
            "Epoch 77/400\n",
            "12/12 [==============================] - 5s 416ms/step - loss: 3.0332 - acc: 0.3280 - val_loss: 3.7057 - val_acc: 0.3672\n",
            "Epoch 78/400\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 3.0247 - acc: 0.3358 - val_loss: 3.2506 - val_acc: 0.4051\n",
            "Epoch 79/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 2.8922 - acc: 0.3467 - val_loss: 3.6679 - val_acc: 0.3329\n",
            "Epoch 80/400\n",
            "12/12 [==============================] - 3s 272ms/step - loss: 2.7287 - acc: 0.3804 - val_loss: 3.4063 - val_acc: 0.3905\n",
            "Epoch 81/400\n",
            "12/12 [==============================] - 4s 366ms/step - loss: 2.7609 - acc: 0.3687 - val_loss: 3.6180 - val_acc: 0.4053\n",
            "Epoch 82/400\n",
            "12/12 [==============================] - 4s 345ms/step - loss: 2.7709 - acc: 0.3573 - val_loss: 3.1856 - val_acc: 0.4199\n",
            "Epoch 83/400\n",
            "12/12 [==============================] - 3s 258ms/step - loss: 2.7689 - acc: 0.3670 - val_loss: 3.5759 - val_acc: 0.3329\n",
            "Epoch 84/400\n",
            "12/12 [==============================] - 3s 266ms/step - loss: 2.8076 - acc: 0.3632 - val_loss: 3.5510 - val_acc: 0.3975\n",
            "Epoch 85/400\n",
            "12/12 [==============================] - 4s 380ms/step - loss: 2.6984 - acc: 0.3783 - val_loss: 3.0991 - val_acc: 0.4544\n",
            "Epoch 86/400\n",
            "12/12 [==============================] - 5s 394ms/step - loss: 2.6745 - acc: 0.3824 - val_loss: 3.5220 - val_acc: 0.3471\n",
            "Epoch 87/400\n",
            "12/12 [==============================] - 3s 257ms/step - loss: 2.6537 - acc: 0.3900 - val_loss: 3.2637 - val_acc: 0.4257\n",
            "Epoch 88/400\n",
            "12/12 [==============================] - 4s 333ms/step - loss: 2.5872 - acc: 0.4244 - val_loss: 3.4578 - val_acc: 0.4441\n",
            "Epoch 89/400\n",
            "12/12 [==============================] - 5s 393ms/step - loss: 2.6737 - acc: 0.3808 - val_loss: 2.9864 - val_acc: 0.4815\n",
            "Epoch 90/400\n",
            "12/12 [==============================] - 5s 397ms/step - loss: 2.6764 - acc: 0.3920 - val_loss: 3.4561 - val_acc: 0.3670\n",
            "Epoch 91/400\n",
            "12/12 [==============================] - 3s 260ms/step - loss: 2.6518 - acc: 0.4024 - val_loss: 3.1607 - val_acc: 0.4552\n",
            "Epoch 92/400\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 2.5442 - acc: 0.4140 - val_loss: 3.3869 - val_acc: 0.4651\n",
            "Epoch 93/400\n",
            "12/12 [==============================] - 4s 325ms/step - loss: 2.3761 - acc: 0.4410 - val_loss: 2.8902 - val_acc: 0.5316\n",
            "Epoch 94/400\n",
            "12/12 [==============================] - 5s 445ms/step - loss: 2.4143 - acc: 0.4337 - val_loss: 3.3945 - val_acc: 0.3798\n",
            "Epoch 95/400\n",
            "12/12 [==============================] - 3s 292ms/step - loss: 2.4228 - acc: 0.4177 - val_loss: 3.1474 - val_acc: 0.4251\n",
            "Epoch 96/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 2.4225 - acc: 0.4281 - val_loss: 3.2885 - val_acc: 0.4868\n",
            "Epoch 97/400\n",
            "12/12 [==============================] - 3s 267ms/step - loss: 2.4565 - acc: 0.4327 - val_loss: 2.8346 - val_acc: 0.5226\n",
            "Epoch 98/400\n",
            "12/12 [==============================] - 6s 494ms/step - loss: 2.3575 - acc: 0.4533 - val_loss: 3.3357 - val_acc: 0.3954\n",
            "Epoch 99/400\n",
            "12/12 [==============================] - 3s 267ms/step - loss: 2.3279 - acc: 0.4617 - val_loss: 3.2424 - val_acc: 0.5132\n",
            "Epoch 100/400\n",
            "12/12 [==============================] - 3s 278ms/step - loss: 2.3233 - acc: 0.4612 - val_loss: 2.7560 - val_acc: 0.5538\n",
            "Epoch 101/400\n",
            "12/12 [==============================] - 3s 266ms/step - loss: 2.2677 - acc: 0.4951 - val_loss: 3.2997 - val_acc: 0.4040\n",
            "Epoch 102/400\n",
            "12/12 [==============================] - 6s 475ms/step - loss: 2.3191 - acc: 0.4665 - val_loss: 2.9572 - val_acc: 0.5198\n",
            "Epoch 103/400\n",
            "12/12 [==============================] - 3s 268ms/step - loss: 2.3319 - acc: 0.4632 - val_loss: 3.1552 - val_acc: 0.5171\n",
            "Epoch 104/400\n",
            "12/12 [==============================] - 3s 269ms/step - loss: 2.3074 - acc: 0.4849 - val_loss: 2.6627 - val_acc: 0.5678\n",
            "Epoch 105/400\n",
            "12/12 [==============================] - 3s 262ms/step - loss: 2.2057 - acc: 0.4889 - val_loss: 3.2540 - val_acc: 0.4196\n",
            "Epoch 106/400\n",
            "12/12 [==============================] - 5s 469ms/step - loss: 2.0322 - acc: 0.5262 - val_loss: 2.8849 - val_acc: 0.5365\n",
            "Epoch 107/400\n",
            "12/12 [==============================] - 4s 276ms/step - loss: 2.0811 - acc: 0.5133 - val_loss: 3.0783 - val_acc: 0.5365\n",
            "Epoch 108/400\n",
            "12/12 [==============================] - 3s 262ms/step - loss: 2.1073 - acc: 0.4921 - val_loss: 2.6009 - val_acc: 0.5859\n",
            "Epoch 109/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 2.0749 - acc: 0.5160 - val_loss: 3.1776 - val_acc: 0.4324\n",
            "Epoch 110/400\n",
            "12/12 [==============================] - 5s 410ms/step - loss: 2.1298 - acc: 0.5063 - val_loss: 2.8296 - val_acc: 0.5455\n",
            "Epoch 111/400\n",
            "12/12 [==============================] - 4s 344ms/step - loss: 2.0337 - acc: 0.5236 - val_loss: 3.0212 - val_acc: 0.5536\n",
            "Epoch 112/400\n",
            "12/12 [==============================] - 3s 253ms/step - loss: 2.0038 - acc: 0.5352 - val_loss: 2.5268 - val_acc: 0.5916\n",
            "Epoch 113/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 2.0057 - acc: 0.5333 - val_loss: 3.1497 - val_acc: 0.4282\n",
            "Epoch 114/400\n",
            "12/12 [==============================] - 4s 343ms/step - loss: 1.9674 - acc: 0.5466 - val_loss: 2.9466 - val_acc: 0.5629\n",
            "Epoch 115/400\n",
            "12/12 [==============================] - 5s 376ms/step - loss: 2.0044 - acc: 0.5337 - val_loss: 2.4439 - val_acc: 0.5949\n",
            "Epoch 116/400\n",
            "12/12 [==============================] - 3s 257ms/step - loss: 2.0077 - acc: 0.5325 - val_loss: 3.0884 - val_acc: 0.4339\n",
            "Epoch 117/400\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 1.9903 - acc: 0.5448 - val_loss: 2.6895 - val_acc: 0.5672\n",
            "Epoch 118/400\n",
            "12/12 [==============================] - 4s 344ms/step - loss: 1.8945 - acc: 0.5606 - val_loss: 2.9305 - val_acc: 0.5613\n",
            "Epoch 119/400\n",
            "12/12 [==============================] - 5s 395ms/step - loss: 1.7250 - acc: 0.5979 - val_loss: 2.3635 - val_acc: 0.6376\n",
            "Epoch 120/400\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 1.7763 - acc: 0.5845 - val_loss: 3.0278 - val_acc: 0.4552\n",
            "Epoch 121/400\n",
            "12/12 [==============================] - 3s 274ms/step - loss: 1.8083 - acc: 0.5672 - val_loss: 2.6378 - val_acc: 0.5787\n",
            "Epoch 122/400\n",
            "12/12 [==============================] - 4s 327ms/step - loss: 1.7728 - acc: 0.5907 - val_loss: 2.8303 - val_acc: 0.5901\n",
            "Epoch 123/400\n",
            "12/12 [==============================] - 5s 422ms/step - loss: 1.8138 - acc: 0.5886 - val_loss: 2.3259 - val_acc: 0.6311\n",
            "Epoch 124/400\n",
            "12/12 [==============================] - 3s 268ms/step - loss: 1.7368 - acc: 0.5996 - val_loss: 2.9855 - val_acc: 0.4580\n",
            "Epoch 125/400\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 1.7169 - acc: 0.6141 - val_loss: 2.5900 - val_acc: 0.5954\n",
            "Epoch 126/400\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 1.7115 - acc: 0.6090 - val_loss: 2.7634 - val_acc: 0.6025\n",
            "Epoch 127/400\n",
            "12/12 [==============================] - 7s 575ms/step - loss: 1.6734 - acc: 0.6191 - val_loss: 2.2440 - val_acc: 0.6450\n",
            "Epoch 128/400\n",
            "12/12 [==============================] - 3s 254ms/step - loss: 1.7084 - acc: 0.6099 - val_loss: 2.9374 - val_acc: 0.4708\n",
            "Epoch 129/400\n",
            "12/12 [==============================] - 3s 263ms/step - loss: 1.7081 - acc: 0.6153 - val_loss: 2.5065 - val_acc: 0.6114\n",
            "Epoch 130/400\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 1.7004 - acc: 0.6250 - val_loss: 2.7083 - val_acc: 0.6141\n",
            "Epoch 131/400\n",
            "12/12 [==============================] - 6s 508ms/step - loss: 1.6131 - acc: 0.6324 - val_loss: 2.1875 - val_acc: 0.6467\n",
            "Epoch 132/400\n",
            "12/12 [==============================] - 3s 269ms/step - loss: 1.4404 - acc: 0.6819 - val_loss: 2.8861 - val_acc: 0.4737\n",
            "Epoch 133/400\n",
            "12/12 [==============================] - 3s 257ms/step - loss: 1.5016 - acc: 0.6577 - val_loss: 2.4513 - val_acc: 0.6255\n",
            "Epoch 134/400\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 1.5284 - acc: 0.6435 - val_loss: 2.6627 - val_acc: 0.6297\n",
            "Epoch 135/400\n",
            " 4/12 [=========>....................] - ETA: 2s - loss: 2.1481 - acc: 0.5643"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-082615c0824e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               metrics=['acc'])\n\u001b[0;32m----> 6\u001b[0;31m history=model.fit_generator(generate_batch(trainX, trainY, batch_size = batch_size),\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history=model.fit_generator(generate_batch(trainX, trainY, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(testX, testY, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size,\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "plt.savefig('accuracy.jpg')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "plt.savefig('loss.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "j3okI71kc_jP",
        "outputId": "1bdbf450-ae06-4e4e-f5c9-583cb2f63041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRP9kIESBm8B"
      },
      "source": [
        "## Save pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "fngNh1c88y01",
        "outputId": "4bb0cf66-9c2d-46e1-fb3a-4208d1a8487c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2cf670727a5b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/hbi/models/machine_v2.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r model_keras_v2.zip /content/drive/MyDrive/hbi/models/machine_v2.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'model_keras_v2.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/MyDrive/hbi/models/machine_v2.keras\")\n",
        "!zip -r model_keras_v2.zip /content/drive/MyDrive/hbi/models/machine_v2.keras\n",
        "from google.colab import files\n",
        "files.download ('model_keras_v2.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "1_PJXwS3_s9_",
        "outputId": "4e22f291-8c3e-45b5-ed2f-3e72ac454aef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m96,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m92,416\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m131,584\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]     │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),    │        \u001b[38;5;34m131,584\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m722\u001b[0m)      │         \u001b[38;5;34m93,138\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">92,416</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]     │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">722</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">93,138</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,089,446\u001b[0m (4.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,446</span> (4.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m544,722\u001b[0m (2.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544,722</span> (2.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m544,724\u001b[0m (2.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544,724</span> (2.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "pretrained_model = tf.keras.models.load_model('/content/drive/MyDrive/hbi/models/machine_v2.keras')\n",
        "# Show the model architecture\n",
        "pretrained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpYwt3T64U4i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkLDkYUjeBSX"
      },
      "outputs": [],
      "source": [
        "pretrained_emb_layer = pretrained_model.get_layer('embedding')\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_emb = pretrained_emb_layer(encoder_inputs)  # Use the pre-trained layer\n",
        "encoder_lstm = pretrained_model.get_layer('lstm')\n",
        "_, state_h, state_c = encoder_lstm(encoder_emb)\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qiw9ZRs1fyXl"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = pretrained_model.get_layer('embedding_1')\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm =pretrained_model.get_layer('lstm_1')\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = pretrained_model.get_layer('dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi86gRR7BaxY"
      },
      "source": [
        "## Encoder/Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ta_EKa4YgC-"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the \"Context vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_state_input,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V1rOpgNYi1b"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = vi_vocabulary[bos]\n",
        "\n",
        "    # Sampling loop for a batch of sequences (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # greedy search\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        # print(output_tokens)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # print(sampled_token_index)\n",
        "        sampled_word =vi_vocabulary_reverse[sampled_token_index]\n",
        "        decoded_sentence += ' '+ sampled_word\n",
        "\n",
        "        # Exit condition: either hit max length or find stop character.\n",
        "        if (sampled_word == eos or\n",
        "           len(decoded_sentence) > 500):\n",
        "            stop_condition = True\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "G9MQsCfZYlLf",
        "outputId": "d7e5efaf-da2c-4d52-cfc0-75a02d4d9bbc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generate_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-996f24f9466a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_gen = generate_batch(testX, testY, batch_size )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (input_seq, actual_output), _ = next(test_gen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_batch' is not defined"
          ]
        }
      ],
      "source": [
        "batch_size=15\n",
        "# test_gen = generate_batch(testX, testY, batch_size )\n",
        "# (input_seq, actual_output), _ = next(test_gen)\n",
        "(input_seq, actual_output), _ = generate_batch(testX, testY)\n",
        "for i in range(batch_size):\n",
        "  seq = input_seq[i]\n",
        "  output = actual_output[i]\n",
        "  decoded_sentence = decode_sequence(np.expand_dims(seq, axis=0))\n",
        "  print(seq)\n",
        "  print('Input Source sentence:', ' '.join([en_vocabulary_reverse[i] for i in seq]))\n",
        "  print('Actual Target Translation:', ' '.join([vi_vocabulary_reverse[i] for i in output]))\n",
        "  print('Predicted Target Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSK1ehMHNtMI"
      },
      "outputs": [],
      "source": [
        "def check_alpha(text):\n",
        "   if text.isalpha():\n",
        "     return True\n",
        "   else:\n",
        "     return False\n",
        "def check_numeric(text):\n",
        "    try:\n",
        "        float(text)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def translate(seq_input):\n",
        "  if type(seq_input)==str:\n",
        "    seq_input = seq_input.lower()\n",
        "  else:\n",
        "    seq_input=str(seq_input)\n",
        "\n",
        "  seq =[tok.text for tok in spacy_en.tokenizer(seq_input)]\n",
        "  print(seq)\n",
        "  if len(seq)==1 and (not check_alpha(seq_input) or check_numeric(seq_input) or len(seq_input)==1):\n",
        "    output = seq_input\n",
        "  else:\n",
        "    # convert sequence to vector\n",
        "    list_isalnum=[]\n",
        "    input_arr = [1]\n",
        "    input_arr_=[1]\n",
        "    # index_next=0\n",
        "    for text in seq:\n",
        "      if text in en_vocabulary and not (check_numeric(text) or not check_alpha(text) or len(text)==1):\n",
        "        input_arr.append(en_vocabulary[text])\n",
        "        input_arr_.append(en_vocabulary[text])\n",
        "      else:\n",
        "        input_arr.append(en_vocabulary['<bos>'])\n",
        "        list_isalnum.append(text)\n",
        "        try:\n",
        "          input_arr_.append(en_vocabulary[text])\n",
        "        except:\n",
        "          input_arr_.append(en_vocabulary['<bos>'])\n",
        "      # try:\n",
        "    if 'i' in list_isalnum and 'd' in list_isalnum:\n",
        "      list_isalnum.remove('i')\n",
        "      list_isalnum.remove('d')\n",
        "      # except:\n",
        "      #   print(\"chưa vào\")\n",
        "    print(list_isalnum)\n",
        "    print(input_arr)\n",
        "    # Translate\n",
        "    if np.unique(input_arr).shape[0] == 1:\n",
        "      output=seq_input\n",
        "    else:\n",
        "      input_arr_ = pad_sequences([input_arr_], maxlen = en_sequence.shape[1], padding = 'post')\n",
        "      print(input_arr_)\n",
        "      decoded_sentence = decode_sequence(input_arr_)\n",
        "      out_str=decoded_sentence[:-5].replace('_', ' ').strip()\n",
        "      print(out_str)\n",
        "      out_list=out_str.split(' ')\n",
        "      print(out_list)\n",
        "      output=\"\"\n",
        "      arr=[]\n",
        "      for index_item, item in enumerate(out_list):\n",
        "        if check_alpha(item):\n",
        "          output+=item+\" \"\n",
        "        else:\n",
        "          arr.append(index_item)\n",
        "      print(arr)\n",
        "      for i in list_isalnum:\n",
        "        spaces_indices = [match.start() for match in re.finditer(' ', output)]\n",
        "        try:\n",
        "          index=arr.pop(0)-1\n",
        "        except:\n",
        "          index=0\n",
        "        output=output[:spaces_indices[index]]+\" \"+i+output[spaces_indices[index]:]\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhsAt2KMrevL",
        "outputId": "5e890af6-cb7c-44af-ff48-5c253f24e3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['added', 'new', 'marker', 'i', 'd', 't148h4', '&', 't148h5']\n",
            "['t148h4', '&', 't148h5']\n",
            "[1, 13, 18, 20, 1, 1, 1, 1, 1]\n",
            "[[  1  13  18  20 187 155 308  36 249   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "đã thêm id rập mới idion theo yêu cầu qua email\n",
            "['đã', 'thêm', 'id', 'rập', 'mới', 'idion', 'theo', 'yêu', 'cầu', 'qua', 'email']\n",
            "[]\n",
            "đã t148h5 & t148h4 thêm id rập mới idion theo yêu cầu qua email \n"
          ]
        }
      ],
      "source": [
        "# text='Added color PGU & IMG to S22'\n",
        "text_='Added new marker ID T148H4 & T148H5'\n",
        "# output=translate(text)\n",
        "output_=translate(text_)\n",
        "# print(output)\n",
        "print(output_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JRP9kIESBm8B"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}